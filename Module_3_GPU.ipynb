{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4pWhxZCyMQ-"
      },
      "source": [
        "# How to run on GPU\n",
        "\n",
        "Step 1) Go to https://github.com/settings/tokens and get a token that can read your private repos\n",
        "\n",
        "Step 2) Clone this colab notebook and change the execution environment to GPU.\n",
        "\n",
        "Step 3) Install python 3.8\n",
        "\n",
        "Step 4) Clone and install your code.\n",
        "\n",
        "Step 5) Run the command-line code for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTzMYZB5yynZ"
      },
      "source": [
        "## Step 3: Install python 3.8\n",
        "Run the cell below without editing it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lciKNd6myIjl",
        "outputId": "a1c89ef8-d7f7-4529-81e3-bf9b86399a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,172 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,613 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.2 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [45.2 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,487 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,223 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,408 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,318 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,449 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [52.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,512 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,732 kB]\n",
            "Fetched 27.5 MB in 5s (5,934 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.12-minimal libpython3.12-stdlib mailcap mime-support\n",
            "  python3.12-minimal\n",
            "Suggested packages:\n",
            "  python3.12-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.12-minimal libpython3.12-stdlib mailcap mime-support python3.12\n",
            "  python3.12-minimal\n",
            "0 upgraded, 6 newly installed, 0 to remove and 57 not upgraded.\n",
            "Need to get 5,548 kB of archives.\n",
            "After this operation, 22.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.12-minimal amd64 3.12.7-1+jammy1 [880 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.12-minimal amd64 3.12.7-1+jammy1 [2,497 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.12-stdlib amd64 3.12.7-1+jammy1 [2,049 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.12 amd64 3.12.7-1+jammy1 [94.7 kB]\n",
            "Fetched 5,548 kB in 6s (943 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.12-minimal:amd64.\n",
            "(Reading database ... 123629 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.12-minimal_3.12.7-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.12-minimal:amd64 (3.12.7-1+jammy1) ...\n",
            "Selecting previously unselected package python3.12-minimal.\n",
            "Preparing to unpack .../1-python3.12-minimal_3.12.7-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.12-minimal (3.12.7-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../3-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.12-stdlib:amd64.\n",
            "Preparing to unpack .../4-libpython3.12-stdlib_3.12.7-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.12-stdlib:amd64 (3.12.7-1+jammy1) ...\n",
            "Selecting previously unselected package python3.12.\n",
            "Preparing to unpack .../5-python3.12_3.12.7-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.12 (3.12.7-1+jammy1) ...\n",
            "Setting up libpython3.12-minimal:amd64 (3.12.7-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up python3.12-minimal (3.12.7-1+jammy1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.12-stdlib:amd64 (3.12.7-1+jammy1) ...\n",
            "Setting up python3.12 (3.12.7-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2222k  100 2222k    0     0  7941k      0 --:--:-- --:--:-- --:--:-- 7937k\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "Successfully installed pip-24.3.1\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.12\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python3.12 get-pip.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guhMlPoey3zE"
      },
      "source": [
        "## Step 4: Clone and install your code\n",
        "First we need to set some environment variables. Get your github API token and MLE repo username and put them into the below variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmmAQK12zJJP",
        "outputId": "930fbcc2-ffca-46ad-84a7-82a0e89f2612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: TOKEN=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\n",
            "env: USER=RD1119\n"
          ]
        }
      ],
      "source": [
        "%env TOKEN=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\n",
        "%env USER=RD1119"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JZt2xZwzS2b"
      },
      "source": [
        "Run the below code. Editing should not be necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYb6KtYFzJjD",
        "outputId": "2eff5395-7f09-42b8-dafa-c674a239199e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: DIR=mod3-RD1119\n",
            "https://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@github.com/Cornell-Tech-ML/mod3-RD1119\n",
            "Cloning into 'mod3-RD1119'...\n",
            "remote: Enumerating objects: 149, done.\u001b[K\n",
            "remote: Counting objects: 100% (114/114), done.\u001b[K\n",
            "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
            "remote: Total 149 (delta 57), reused 44 (delta 35), pack-reused 35 (from 1)\u001b[K\n",
            "Receiving objects: 100% (149/149), 160.70 KiB | 866.00 KiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Collecting colorama==0.4.3 (from -r requirements.txt (line 1))\n",
            "  Downloading colorama-0.4.3-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting hypothesis==6.54 (from -r requirements.txt (line 2))\n",
            "  Downloading hypothesis-6.54.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting numba==0.60 (from -r requirements.txt (line 3))\n",
            "  Downloading numba-0.60.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numpy==2.0.0 (from -r requirements.txt (line 4))\n",
            "  Downloading numpy-2.0.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting pre-commit==2.20.0 (from -r requirements.txt (line 5))\n",
            "  Downloading pre_commit-2.20.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting pytest==8.3.2 (from -r requirements.txt (line 6))\n",
            "  Downloading pytest-8.3.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pytest-env (from -r requirements.txt (line 7))\n",
            "  Downloading pytest_env-1.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pytest-runner==5.2 (from -r requirements.txt (line 8))\n",
            "  Downloading pytest_runner-5.2-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting typing_extensions (from -r requirements.txt (line 9))\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting attrs>=19.2.0 (from hypothesis==6.54->-r requirements.txt (line 2))\n",
            "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis==6.54->-r requirements.txt (line 2))\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba==0.60->-r requirements.txt (line 3))\n",
            "  Downloading llvmlite-0.43.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading identify-2.6.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pyyaml>=5.1 (from pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting toml (from pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting virtualenv>=20.0.8 (from pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading virtualenv-20.27.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting iniconfig (from pytest==8.3.2->-r requirements.txt (line 6))\n",
            "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting packaging (from pytest==8.3.2->-r requirements.txt (line 6))\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pluggy<2,>=1.5 (from pytest==8.3.2->-r requirements.txt (line 6))\n",
            "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "INFO: pip is looking at multiple versions of pytest-env to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pytest-env (from -r requirements.txt (line 7))\n",
            "  Downloading pytest_env-1.1.4-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting filelock<4,>=3.12.2 (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting platformdirs<5,>=3.9.1 (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\n",
            "Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
            "Downloading hypothesis-6.54.0-py3-none-any.whl (389 kB)\n",
            "Downloading numba-0.60.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.0.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-2.20.0-py2.py3-none-any.whl (199 kB)\n",
            "Downloading pytest-8.3.2-py3-none-any.whl (341 kB)\n",
            "Downloading pytest_runner-5.2-py2.py3-none-any.whl (6.8 kB)\n",
            "Downloading pytest_env-1.1.4-py3-none-any.whl (6.2 kB)\n",
            "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
            "Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading identify-2.6.2-py2.py3-none-any.whl (98 kB)\n",
            "Downloading llvmlite-0.43.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
            "Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading virtualenv-20.27.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
            "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: sortedcontainers, distlib, typing_extensions, toml, pyyaml, pytest-runner, pluggy, platformdirs, packaging, numpy, nodeenv, llvmlite, iniconfig, identify, filelock, colorama, cfgv, attrs, virtualenv, pytest, numba, hypothesis, pytest-env, pre-commit\n",
            "Successfully installed attrs-24.2.0 cfgv-3.4.0 colorama-0.4.3 distlib-0.3.9 filelock-3.16.1 hypothesis-6.54.0 identify-2.6.2 iniconfig-2.0.0 llvmlite-0.43.0 nodeenv-1.9.1 numba-0.60.0 numpy-2.0.0 packaging-24.2 platformdirs-4.3.6 pluggy-1.5.0 pre-commit-2.20.0 pytest-8.3.2 pytest-env-1.1.4 pytest-runner-5.2 pyyaml-6.0.2 sortedcontainers-2.4.0 toml-0.10.2 typing_extensions-4.12.2 virtualenv-20.27.1\n",
            "Collecting altair==4.2.2 (from -r requirements.extra.txt (line 1))\n",
            "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting datasets==2.4.0 (from -r requirements.extra.txt (line 2))\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting embeddings==0.0.8 (from -r requirements.extra.txt (line 3))\n",
            "  Downloading embeddings-0.0.8-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting networkx==3.3 (from -r requirements.extra.txt (line 4))\n",
            "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting plotly==4.14.3 (from -r requirements.extra.txt (line 5))\n",
            "  Downloading plotly-4.14.3-py2.py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting pydot==1.4.1 (from -r requirements.extra.txt (line 6))\n",
            "  Downloading pydot-1.4.1-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting python-mnist (from -r requirements.extra.txt (line 7))\n",
            "  Downloading python_mnist-0.7-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting streamlit==1.12.0 (from -r requirements.extra.txt (line 8))\n",
            "  Downloading streamlit-1.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting streamlit-ace (from -r requirements.extra.txt (line 9))\n",
            "  Downloading streamlit_ace-0.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting torch (from -r requirements.extra.txt (line 10))\n",
            "  Downloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting watchdog==1.0.2 (from -r requirements.extra.txt (line 11))\n",
            "  Downloading watchdog-1.0.2-py3-none-manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Collecting entrypoints (from altair==4.2.2->-r requirements.extra.txt (line 1))\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting jinja2 (from altair==4.2.2->-r requirements.extra.txt (line 1))\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting jsonschema>=3.0 (from altair==4.2.2->-r requirements.extra.txt (line 1))\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from altair==4.2.2->-r requirements.extra.txt (line 1)) (2.0.0)\n",
            "Collecting pandas>=0.18 (from altair==4.2.2->-r requirements.extra.txt (line 1))\n",
            "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting toolz (from altair==4.2.2->-r requirements.extra.txt (line 1))\n",
            "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pyarrow>=6.0.0 (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading pyarrow-18.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.6 (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting requests>=2.19.0 (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tqdm>=4.62.1 (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting xxhash (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2021.11.1 (from fsspec[http]>=2021.11.1->datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading aiohttp-3.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0 (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (24.2)\n",
            "Collecting responses<0.19 (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting retrying>=1.3.3 (from plotly==4.14.3->-r requirements.extra.txt (line 5))\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from plotly==4.14.3->-r requirements.extra.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/lib/python3/dist-packages (from pydot==1.4.1->-r requirements.extra.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (1.4)\n",
            "Collecting cachetools>=4.0 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting click>=7.0 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/lib/python3/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (4.6.4)\n",
            "Collecting pillow>=6.2.0 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting protobuf<4,>=3.12 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Collecting pydeck>=0.1.dev5 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pympler>=0.9 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading Pympler-1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting python-dateutil (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting rich>=10.11.0 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting semver (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (0.10.2)\n",
            "Collecting tornado>=5.0 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (4.12.2)\n",
            "Collecting tzlocal>=1.1 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting validators>=0.2 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting gitpython!=3.1.19 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (3.16.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting setuptools (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting sympy==1.13.1 (from torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->-r requirements.extra.txt (line 10))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (24.2.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading propcache-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading yarl-1.17.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (66 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19->streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.4.0->-r requirements.extra.txt (line 2)) (6.0.2)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair==4.2.2->-r requirements.extra.txt (line 1))\n",
            "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair==4.2.2->-r requirements.extra.txt (line 1))\n",
            "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair==4.2.2->-r requirements.extra.txt (line 1))\n",
            "  Downloading rpds_py-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=0.18->altair==4.2.2->-r requirements.extra.txt (line 1))\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=0.18->altair==4.2.2->-r requirements.extra.txt (line 1))\n",
            "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->altair==4.2.2->-r requirements.extra.txt (line 1))\n",
            "  Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading multiprocess-0.70.13-py310-none-any.whl.metadata (6.8 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "Downloading embeddings-0.0.8-py3-none-any.whl (12 kB)\n",
            "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m129.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydot-1.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Downloading streamlit-1.12.0-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m130.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-1.0.2-py3-none-manylinux2014_x86_64.whl (72 kB)\n",
            "Downloading python_mnist-0.7-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading streamlit_ace-0.1.1-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
            "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "Downloading aiohttp-3.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
            "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "Downloading pyarrow-18.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (40.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "Downloading Pympler-1.1-py3-none-any.whl (165 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Downloading tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
            "Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
            "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
            "Downloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Downloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\n",
            "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Downloading setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
            "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "Downloading charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
            "Downloading propcache-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (248 kB)\n",
            "Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (364 kB)\n",
            "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "Downloading yarl-1.17.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pytz, python-mnist, mpmath, xxhash, watchdog, validators, urllib3, tzlocal, tzdata, triton, tqdm, tornado, toolz, sympy, smmap, setuptools, semver, rpds-py, retrying, python-dateutil, pympler, pygments, pydot, pyarrow, protobuf, propcache, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, multidict, mdurl, MarkupSafe, idna, fsspec, frozenlist, entrypoints, dill, click, charset-normalizer, certifi, cachetools, aiohappyeyeballs, yarl, requests, referencing, plotly, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, markdown-it-py, jinja2, gitdb, aiosignal, rich, responses, pydeck, nvidia-cusolver-cu12, jsonschema-specifications, huggingface-hub, gitpython, embeddings, aiohttp, torch, jsonschema, datasets, altair, streamlit, streamlit-ace\n",
            "Successfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.4.3 aiohttp-3.11.6 aiosignal-1.3.1 altair-4.2.2 cachetools-5.5.0 certifi-2024.8.30 charset-normalizer-3.4.0 click-8.1.7 datasets-2.4.0 dill-0.3.5.1 embeddings-0.0.8 entrypoints-0.4 frozenlist-1.5.0 fsspec-2024.10.0 gitdb-4.0.11 gitpython-3.1.43 huggingface-hub-0.26.2 idna-3.10 jinja2-3.1.4 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 markdown-it-py-3.0.0 mdurl-0.1.2 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.13 networkx-3.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pandas-2.2.3 pillow-11.0.0 plotly-4.14.3 propcache-0.2.0 protobuf-3.20.3 pyarrow-18.0.0 pydeck-0.9.1 pydot-1.4.1 pygments-2.18.0 pympler-1.1 python-dateutil-2.9.0.post0 python-mnist-0.7 pytz-2024.2 referencing-0.35.1 requests-2.32.3 responses-0.18.0 retrying-1.3.4 rich-13.9.4 rpds-py-0.21.0 semver-3.0.2 setuptools-75.6.0 smmap-5.0.1 streamlit-1.12.0 streamlit-ace-0.1.1 sympy-1.13.1 toolz-1.0.0 torch-2.5.1 tornado-6.4.1 tqdm-4.67.0 triton-3.1.0 tzdata-2024.2 tzlocal-5.2 urllib3-2.2.3 validators-0.34.0 watchdog-1.0.2 xxhash-3.5.0 yarl-1.17.2\n",
            "Processing /content/mod3-RD1119\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: minitorch\n",
            "  Building wheel for minitorch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minitorch: filename=minitorch-0.5-py2.py3-none-any.whl size=31615 sha256=6d42a31106d3d6fa2e2b865714d8813dbb24a6f57753dc0c00866fcb820fbc4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/bd/65/62807f26aa8f5d5247cf72202e3c2b0a35f528b053d1cc358c\n",
            "Successfully built minitorch\n",
            "Installing collected packages: minitorch\n",
            "Successfully installed minitorch-0.5\n"
          ]
        }
      ],
      "source": [
        "TOKEN = %env TOKEN\n",
        "USER = %env USER\n",
        "#%env DIR=mle-module-3-$USER\n",
        "%env DIR=mod3-$USER\n",
        "DIR = %env DIR\n",
        "\n",
        "!echo https://$TOKEN@github.com/Cornell-Tech-ML/$DIR\n",
        "\n",
        "!git clone -b master --single-branch https://$TOKEN@github.com/Cornell-Tech-ML/$DIR\n",
        "!cd $DIR; pip3.12 install -r requirements.txt; pip3.12 install -r requirements.extra.txt; pip3.12 install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2xn5AhUzaW_"
      },
      "source": [
        "If you update your code, you can re-pull the repo by running this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GywpmTnozf26",
        "outputId": "d2a0e070-c39b-46b0-d453-fa59d5f0c8ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/Cornell-Tech-ML/mod3-RD1119\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n",
            "Processing /content/mod3-RD1119\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: minitorch\n",
            "  Building wheel for minitorch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minitorch: filename=minitorch-0.5-py2.py3-none-any.whl size=31615 sha256=6d42a31106d3d6fa2e2b865714d8813dbb24a6f57753dc0c00866fcb820fbc4f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s5_wgtij/wheels/a8/bd/65/62807f26aa8f5d5247cf72202e3c2b0a35f528b053d1cc358c\n",
            "Successfully built minitorch\n",
            "Installing collected packages: minitorch\n",
            "  Attempting uninstall: minitorch\n",
            "    Found existing installation: minitorch 0.5\n",
            "    Uninstalling minitorch-0.5:\n",
            "      Successfully uninstalled minitorch-0.5\n",
            "Successfully installed minitorch-0.5\n"
          ]
        }
      ],
      "source": [
        "!cd $DIR; git pull origin master; pip3.12 install --force-reinstall --no-cache-dir ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Pytest"
      ],
      "metadata": {
        "id": "OJI2w775POnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9GsVaqr8wlg",
        "outputId": "6b9a4178-070e-488a-b139-b078c26e20fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.12.7, pytest-8.3.2, pluggy-1.5.0\n",
            "rootdir: /content/mod3-RD1119\n",
            "configfile: pyproject.toml\n",
            "plugins: hypothesis-6.54.0, env-1.1.4\n",
            "collected 117 items                                                                                \u001b[0m\n",
            "\n",
            "tests/test_tensor_general.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m [ 53%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                       [100%]\u001b[0m\n",
            "\n",
            "\u001b[33m========================================= warnings summary =========================================\u001b[0m\n",
            "tests/test_tensor_general.py: 20 warnings\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py: 4377 warnings\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py: 15 warnings\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_args[cuda-fn2]\n",
            "tests/test_tensor_general.py::test_one_args[cuda-fn4]\n",
            "tests/test_tensor_general.py::test_one_args[cuda-fn10]\n",
            "tests/test_tensor_general.py::test_two_args[cuda-fn3]\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn4]\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn11]\n",
            "tests/test_tensor_general.py::test_sum_practice2\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 3 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 6 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 18 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 9 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 27 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "tests/test_tensor_general.py::test_mul_practice4\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn1]\n",
            "tests/test_tensor_general.py::test_mul_practice5\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn3]\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 12 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_sum_practice_other_dims\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_mul_practice4\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 35 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 48 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 5 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 36 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 24 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
            "\u001b[33m========================== \u001b[32m117 passed\u001b[0m, \u001b[33m\u001b[1m4440 warnings\u001b[0m\u001b[33m in 282.32s (0:04:42)\u001b[0m\u001b[33m ==========================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR pytest tests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Timing.py"
      ],
      "metadata": {
        "id": "Q8xgNdYkPWN5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Pj62tthe_B60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea1bdeb9-4dec-4abb-af91-2754fa60c89d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 2 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Running size 64\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 8 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "{'fast': 0.003416299819946289, 'gpu': 0.006405274073282878}\n",
            "Running size 128\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 32 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "{'fast': 0.015821377436319988, 'gpu': 0.014887491861979166}\n",
            "Running size 256\n",
            "{'fast': 0.09493605295817058, 'gpu': 0.05744067827860514}\n",
            "Running size 512\n",
            "{'fast': 1.074148178100586, 'gpu': 0.21904579798380533}\n",
            "Running size 1024\n",
            "{'fast': 7.842411994934082, 'gpu': 0.99863068262736}\n",
            "\n",
            "Timing summary\n",
            "Size: 64\n",
            "    fast: 0.00342\n",
            "    gpu: 0.00641\n",
            "Size: 128\n",
            "    fast: 0.01582\n",
            "    gpu: 0.01489\n",
            "Size: 256\n",
            "    fast: 0.09494\n",
            "    gpu: 0.05744\n",
            "Size: 512\n",
            "    fast: 1.07415\n",
            "    gpu: 0.21905\n",
            "Size: 1024\n",
            "    fast: 7.84241\n",
            "    gpu: 0.99863\n",
            "Fast_times [0.003416299819946289, 0.015821377436319988, 0.09493605295817058, 1.074148178100586, 7.842411994934082]\n",
            "gpu_times [0.006405274073282878, 0.014887491861979166, 0.05744067827860514, 0.21904579798380533, 0.99863068262736]\n"
          ]
        }
      ],
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3 timing.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Draw the result"
      ],
      "metadata": {
        "id": "3ewObvX7PbUw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "A4wm4Ojt8iDJ",
        "outputId": "5c4bff33-abbf-4bbd-92ed-3f5891e3324a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data from the provided results\n",
        "sizes = [64, 128, 256, 512, 1024]  # Sizes of the square matrices\n",
        "fast_times = [0.003416299819946289, 0.015821377436319988, 0.09493605295817058, 1.074148178100586, 7.842411994934082]  # Execution times for FastOps\n",
        "gpu_times = [0.006405274073282878, 0.014887491861979166, 0.05744067827860514, 0.21904579798380533, 0.99863068262736]  # Execution times for CudaOps\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(sizes, fast_times, label='FastOps', marker='o', color='blue')\n",
        "plt.plot(sizes, gpu_times, label='CudaOps', marker='x', color='red')\n",
        "plt.xlabel('Matrix Size (n x n)')\n",
        "plt.ylabel('Execution Time (s)')\n",
        "plt.title('Comparison of Matrix Multiplication Execution Time')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qufLzTGmzs1K"
      },
      "source": [
        "## Step 5: Run the training command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FY8Q4MqEzvGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffecbb41-fc5d-48ad-9092-487c2a1aa53c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 100 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Epoch  0  loss  7.030329622322549 correct 29 Time per epoch 0.38790576457977294\n",
            "Epoch  10  loss  4.496681386710301 correct 26 Time per epoch 1.6367682933807373\n",
            "Epoch  20  loss  6.128431978335912 correct 36 Time per epoch 1.5687076330184937\n",
            "Epoch  30  loss  4.370202298858919 correct 46 Time per epoch 1.561046314239502\n",
            "Epoch  40  loss  3.6281915183647877 correct 46 Time per epoch 1.576847457885742\n",
            "Epoch  50  loss  3.1357959770227106 correct 45 Time per epoch 1.6455533742904662\n",
            "Epoch  60  loss  2.162244334070718 correct 47 Time per epoch 1.5567980766296388\n",
            "Epoch  70  loss  2.6602194450890453 correct 45 Time per epoch 1.5652177810668946\n",
            "Epoch  80  loss  2.7124660858865672 correct 43 Time per epoch 1.7340365171432495\n",
            "Epoch  90  loss  1.6830174686967776 correct 48 Time per epoch 1.5639925956726075\n",
            "Epoch  100  loss  2.4295431377832513 correct 43 Time per epoch 1.562187623977661\n",
            "Epoch  110  loss  1.6566031100281162 correct 47 Time per epoch 1.5683364391326904\n",
            "Epoch  120  loss  2.1416442367919024 correct 47 Time per epoch 1.6363176822662353\n",
            "Epoch  130  loss  1.243159113703022 correct 48 Time per epoch 1.5588584184646606\n",
            "Epoch  140  loss  1.9213199064366395 correct 45 Time per epoch 1.5601646661758424\n",
            "Epoch  150  loss  2.2682643219923673 correct 48 Time per epoch 1.6348508596420288\n",
            "Epoch  160  loss  1.5838061958529246 correct 50 Time per epoch 1.5631211996078491\n",
            "Epoch  170  loss  1.8281198092424555 correct 49 Time per epoch 1.5629527807235717\n",
            "Epoch  180  loss  1.3376825719361338 correct 50 Time per epoch 1.5753697872161865\n",
            "Epoch  190  loss  1.1465268072414005 correct 46 Time per epoch 1.6182536602020263\n",
            "Epoch  200  loss  1.006569316897611 correct 48 Time per epoch 1.5613746166229248\n",
            "Epoch  210  loss  3.4060009951335757 correct 47 Time per epoch 1.5633638858795167\n",
            "Epoch  220  loss  4.264992780290969 correct 48 Time per epoch 1.6390291452407837\n",
            "Epoch  230  loss  0.8531605009705876 correct 50 Time per epoch 1.5603173494338989\n",
            "Epoch  240  loss  6.130987642861223 correct 38 Time per epoch 1.5764514684677124\n",
            "Epoch  250  loss  2.5826707630260684 correct 47 Time per epoch 1.5795851230621338\n",
            "Epoch  260  loss  1.1080700590362655 correct 48 Time per epoch 1.622667956352234\n",
            "Epoch  270  loss  0.7314500832138859 correct 45 Time per epoch 1.6566795587539673\n",
            "Epoch  280  loss  1.305768182815533 correct 47 Time per epoch 1.550727367401123\n",
            "Epoch  290  loss  1.0535672113660866 correct 49 Time per epoch 1.6345623016357422\n",
            "Epoch  300  loss  1.7207453308019889 correct 50 Time per epoch 1.5590502500534058\n",
            "Epoch  310  loss  0.5018154470962541 correct 45 Time per epoch 1.5623395919799805\n",
            "Epoch  320  loss  1.179527347257625 correct 49 Time per epoch 1.5539769649505615\n",
            "Epoch  330  loss  0.8173735946007702 correct 47 Time per epoch 1.6320308923721314\n",
            "Epoch  340  loss  2.0692489647649293 correct 48 Time per epoch 1.5556090593338012\n",
            "Epoch  350  loss  1.831574086915719 correct 50 Time per epoch 1.5602456092834474\n",
            "Epoch  360  loss  0.8058495521517599 correct 50 Time per epoch 1.6063069820404052\n",
            "Epoch  370  loss  1.126596935163321 correct 47 Time per epoch 1.5792619943618775\n",
            "Epoch  380  loss  1.5734018531253877 correct 47 Time per epoch 1.5524924516677856\n",
            "Epoch  390  loss  1.3064163183416955 correct 49 Time per epoch 1.56344735622406\n",
            "Epoch  400  loss  0.8470412570068735 correct 50 Time per epoch 1.6317063331604005\n",
            "Epoch  410  loss  0.37325089955354207 correct 50 Time per epoch 1.554289197921753\n",
            "Epoch  420  loss  0.794281589998707 correct 50 Time per epoch 1.5523608922958374\n",
            "Epoch  430  loss  0.1200985647721971 correct 47 Time per epoch 1.6176042795181274\n",
            "Epoch  440  loss  1.1198057735316644 correct 50 Time per epoch 1.5906382560729981\n",
            "Epoch  450  loss  0.45207294402710496 correct 50 Time per epoch 1.5524711608886719\n",
            "Epoch  460  loss  1.0801616462274302 correct 50 Time per epoch 1.5584780693054199\n",
            "Epoch  470  loss  0.8228507731021052 correct 49 Time per epoch 1.7180626392364502\n",
            "Epoch  480  loss  1.2685997379897098 correct 50 Time per epoch 1.5610052585601806\n",
            "Epoch  490  loss  1.3596379225545836 correct 50 Time per epoch 1.547406053543091\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 100 --DATASET split --RATE 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RvzWOWT_tKZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00db3059-21ad-4e2c-ebe0-4b89339ba2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0  loss  6.641579905541806 correct 28 Time per epoch 1.435877799987793\n",
            "Epoch  10  loss  5.02394374441548 correct 39 Time per epoch 0.13884754180908204\n",
            "Epoch  20  loss  5.0456205238833505 correct 35 Time per epoch 0.20109705924987792\n",
            "Epoch  30  loss  3.7758766118571194 correct 45 Time per epoch 0.11016435623168945\n",
            "Epoch  40  loss  5.013064862517209 correct 47 Time per epoch 0.11224696636199952\n",
            "Epoch  50  loss  3.1928480765096827 correct 48 Time per epoch 0.11033351421356201\n",
            "Epoch  60  loss  1.898677206465932 correct 47 Time per epoch 0.11016056537628174\n",
            "Epoch  70  loss  1.6926557361662378 correct 48 Time per epoch 0.10958619117736816\n",
            "Epoch  80  loss  2.6076206100632975 correct 46 Time per epoch 0.111328387260437\n",
            "Epoch  90  loss  1.1044360522360688 correct 48 Time per epoch 0.10992507934570313\n",
            "Epoch  100  loss  0.5192699155888002 correct 47 Time per epoch 0.1095463514328003\n",
            "Epoch  110  loss  0.7293814221777412 correct 48 Time per epoch 0.11776885986328126\n",
            "Epoch  120  loss  1.4604518146580094 correct 48 Time per epoch 0.2018970251083374\n",
            "Epoch  130  loss  1.0012174708939476 correct 49 Time per epoch 0.12511012554168702\n",
            "Epoch  140  loss  0.46013293933984245 correct 49 Time per epoch 0.11060826778411866\n",
            "Epoch  150  loss  1.5640321819505851 correct 49 Time per epoch 0.10989663600921631\n",
            "Epoch  160  loss  0.4776525076228509 correct 48 Time per epoch 0.11024856567382812\n",
            "Epoch  170  loss  0.5219268148694662 correct 50 Time per epoch 0.10896446704864501\n",
            "Epoch  180  loss  1.9039126853449382 correct 48 Time per epoch 0.10982873439788818\n",
            "Epoch  190  loss  2.651305045391856 correct 46 Time per epoch 0.11057426929473876\n",
            "Epoch  200  loss  0.21443530289773122 correct 47 Time per epoch 0.11156687736511231\n",
            "Epoch  210  loss  0.8028541093197802 correct 49 Time per epoch 0.11119260787963867\n",
            "Epoch  220  loss  0.247567803453427 correct 49 Time per epoch 0.1933891534805298\n",
            "Epoch  230  loss  0.9880156754923732 correct 49 Time per epoch 0.14403142929077148\n",
            "Epoch  240  loss  0.5045651004385868 correct 48 Time per epoch 0.11205062866210938\n",
            "Epoch  250  loss  0.36031219207861975 correct 49 Time per epoch 0.10969560146331787\n",
            "Epoch  260  loss  0.4058905151236129 correct 49 Time per epoch 0.12019131183624268\n",
            "Epoch  270  loss  0.6611211506402405 correct 50 Time per epoch 0.11002864837646484\n",
            "Epoch  280  loss  0.8141287485185503 correct 49 Time per epoch 0.10982601642608643\n",
            "Epoch  290  loss  0.37206560607705824 correct 47 Time per epoch 0.11095519065856933\n",
            "Epoch  300  loss  0.31264022949534387 correct 50 Time per epoch 0.10984270572662354\n",
            "Epoch  310  loss  2.3265267659102475 correct 47 Time per epoch 0.1095996618270874\n",
            "Epoch  320  loss  3.3183812978696006 correct 48 Time per epoch 0.18856408596038818\n",
            "Epoch  330  loss  0.5566749662574594 correct 49 Time per epoch 0.14541981220245362\n",
            "Epoch  340  loss  0.6451899287347702 correct 49 Time per epoch 0.10907857418060303\n",
            "Epoch  350  loss  0.7620634570908436 correct 49 Time per epoch 0.1096238374710083\n",
            "Epoch  360  loss  1.0949108440881876 correct 48 Time per epoch 0.10984199047088623\n",
            "Epoch  370  loss  1.164550791590681 correct 50 Time per epoch 0.1108816385269165\n",
            "Epoch  380  loss  0.8764573431935663 correct 49 Time per epoch 0.10905251502990723\n",
            "Epoch  390  loss  0.16546967803650747 correct 49 Time per epoch 0.10902657508850097\n",
            "Epoch  400  loss  1.135167294115634 correct 50 Time per epoch 0.10967147350311279\n",
            "Epoch  410  loss  0.42901456007970606 correct 50 Time per epoch 0.10937027931213379\n",
            "Epoch  420  loss  0.04380896140439232 correct 49 Time per epoch 0.16070556640625\n",
            "Epoch  430  loss  0.14562949286234814 correct 49 Time per epoch 0.17720882892608641\n",
            "Epoch  440  loss  0.3200063404653361 correct 50 Time per epoch 0.10823979377746581\n",
            "Epoch  450  loss  0.2903542998082129 correct 50 Time per epoch 0.10912513732910156\n",
            "Epoch  460  loss  0.7944141668323299 correct 50 Time per epoch 0.11001882553100586\n",
            "Epoch  470  loss  1.0851101437286794 correct 49 Time per epoch 0.10805928707122803\n",
            "Epoch  480  loss  0.3666256340905247 correct 50 Time per epoch 0.10782449245452881\n",
            "Epoch  490  loss  0.24195862283988362 correct 49 Time per epoch 0.11262617111206055\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 100 --DATASET split --RATE 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iS9NKsjEQF6",
        "outputId": "0ab8da91-233e-469e-9e45-7275e44272cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 100 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Epoch  0  loss  4.231057618503737 correct 40 Time per epoch 0.4488811016082764\n",
            "Epoch  10  loss  0.8467802908955622 correct 49 Time per epoch 1.5690074920654298\n",
            "Epoch  20  loss  1.6482978034940654 correct 48 Time per epoch 1.5706833124160766\n",
            "Epoch  30  loss  0.6324838504066655 correct 48 Time per epoch 1.642581057548523\n",
            "Epoch  40  loss  0.8950996673174823 correct 49 Time per epoch 1.5805742502212525\n",
            "Epoch  50  loss  0.557809176628955 correct 48 Time per epoch 1.570874238014221\n",
            "Epoch  60  loss  1.3102887662350673 correct 50 Time per epoch 1.6063580989837647\n",
            "Epoch  70  loss  1.697801879824845 correct 48 Time per epoch 1.6199917793273926\n",
            "Epoch  80  loss  0.08106413440341503 correct 48 Time per epoch 1.5719878435134889\n",
            "Epoch  90  loss  0.4067537828134001 correct 48 Time per epoch 1.5644217252731323\n",
            "Epoch  100  loss  0.0742427889841448 correct 50 Time per epoch 1.6503339767456056\n",
            "Epoch  110  loss  0.4756091691101141 correct 49 Time per epoch 1.6955562353134155\n",
            "Epoch  120  loss  1.3418731025636523 correct 49 Time per epoch 1.5934258222579956\n",
            "Epoch  130  loss  0.5380740192756103 correct 49 Time per epoch 1.6679628849029542\n",
            "Epoch  140  loss  0.012924391166384386 correct 49 Time per epoch 1.5774704456329345\n",
            "Epoch  150  loss  0.007138768457189043 correct 47 Time per epoch 1.5773017406463623\n",
            "Epoch  160  loss  0.1521845876640417 correct 50 Time per epoch 1.6427552938461303\n",
            "Epoch  170  loss  0.06101198209403101 correct 50 Time per epoch 1.576206588745117\n",
            "Epoch  180  loss  0.36331552958001045 correct 49 Time per epoch 1.5633602857589721\n",
            "Epoch  190  loss  0.6858176067364078 correct 50 Time per epoch 1.5948326349258424\n",
            "Epoch  200  loss  0.8743589780061779 correct 48 Time per epoch 1.6196994304656982\n",
            "Epoch  210  loss  0.9137573520419653 correct 50 Time per epoch 1.5781194925308228\n",
            "Epoch  220  loss  0.12973097008031595 correct 50 Time per epoch 1.5659207344055175\n",
            "Epoch  230  loss  0.333473533519198 correct 49 Time per epoch 1.6490115165710448\n",
            "Epoch  240  loss  0.5801070481921121 correct 49 Time per epoch 1.5623791217803955\n",
            "Epoch  250  loss  0.44292662517255305 correct 49 Time per epoch 1.5688508749008179\n",
            "Epoch  260  loss  1.2806590539121183 correct 50 Time per epoch 1.6387576341629029\n",
            "Epoch  270  loss  0.7524215291097837 correct 50 Time per epoch 1.5839954614639282\n",
            "Epoch  280  loss  0.659093157008466 correct 50 Time per epoch 1.5667675018310547\n",
            "Epoch  290  loss  0.08920144568287817 correct 50 Time per epoch 1.5662221670150758\n",
            "Epoch  300  loss  1.6115410218755684 correct 48 Time per epoch 1.743427538871765\n",
            "Epoch  310  loss  0.86187292769938 correct 50 Time per epoch 1.5690655708312988\n",
            "Epoch  320  loss  0.5156947497816096 correct 49 Time per epoch 1.5733680963516234\n",
            "Epoch  330  loss  0.5976275455953565 correct 49 Time per epoch 1.6447987794876098\n",
            "Epoch  340  loss  0.11143267311434368 correct 49 Time per epoch 1.5705573797225951\n",
            "Epoch  350  loss  0.4709308173535459 correct 49 Time per epoch 1.5632790327072144\n",
            "Epoch  360  loss  1.7302280438197948 correct 48 Time per epoch 1.5826247930526733\n",
            "Epoch  370  loss  1.135732244371917 correct 50 Time per epoch 1.631567358970642\n",
            "Epoch  380  loss  0.7934008748515493 correct 49 Time per epoch 1.5881070852279664\n",
            "Epoch  390  loss  0.7718463037146869 correct 50 Time per epoch 1.5788071393966674\n",
            "Epoch  400  loss  1.6858438734811 correct 48 Time per epoch 1.660209321975708\n",
            "Epoch  410  loss  0.16169846891747558 correct 49 Time per epoch 1.5730446815490722\n",
            "Epoch  420  loss  1.1804958734110034 correct 50 Time per epoch 1.5614545345306396\n",
            "Epoch  430  loss  0.006436953273244205 correct 50 Time per epoch 1.618458914756775\n",
            "Epoch  440  loss  0.5896515584878574 correct 50 Time per epoch 1.5990609169006347\n",
            "Epoch  450  loss  0.23801012726541856 correct 50 Time per epoch 1.5805660724639892\n",
            "Epoch  460  loss  0.20424528272422537 correct 50 Time per epoch 1.5661282777786254\n",
            "Epoch  470  loss  0.5736815671557478 correct 49 Time per epoch 1.647271203994751\n",
            "Epoch  480  loss  0.025648743403433344 correct 49 Time per epoch 1.5685143232345582\n",
            "Epoch  490  loss  0.4852364551562155 correct 50 Time per epoch 1.566480803489685\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 100 --DATASET simple --RATE 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T1I7cAmtOcW",
        "outputId": "3559994a-4cda-4d3b-f8f2-3f46d388ae43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0  loss  4.7964597120985655 correct 45 Time per epoch 1.4510001420974732\n",
            "Epoch  10  loss  1.843893697153623 correct 49 Time per epoch 0.18239452838897705\n",
            "Epoch  20  loss  1.1800711870149345 correct 47 Time per epoch 0.15107412338256837\n",
            "Epoch  30  loss  1.1379222704817513 correct 49 Time per epoch 0.11080653667449951\n",
            "Epoch  40  loss  1.5238688027902942 correct 50 Time per epoch 0.1107985258102417\n",
            "Epoch  50  loss  1.0257448933380902 correct 49 Time per epoch 0.11265122890472412\n",
            "Epoch  60  loss  1.3678295992416851 correct 50 Time per epoch 0.11178324222564698\n",
            "Epoch  70  loss  0.6147506460680406 correct 49 Time per epoch 0.11113805770874023\n",
            "Epoch  80  loss  1.330776877652118 correct 50 Time per epoch 0.11076166629791259\n",
            "Epoch  90  loss  0.30768964966024254 correct 50 Time per epoch 0.11039502620697021\n",
            "Epoch  100  loss  1.0228521731630231 correct 50 Time per epoch 0.11044423580169678\n",
            "Epoch  110  loss  0.22464174361273043 correct 50 Time per epoch 0.17132461071014404\n",
            "Epoch  120  loss  2.1040612290873737 correct 47 Time per epoch 0.17105562686920167\n",
            "Epoch  130  loss  0.5359279796223502 correct 50 Time per epoch 0.11143200397491455\n",
            "Epoch  140  loss  0.3934004666180992 correct 49 Time per epoch 0.11094987392425537\n",
            "Epoch  150  loss  0.9526635705044021 correct 49 Time per epoch 0.11008434295654297\n",
            "Epoch  160  loss  0.6443498056264325 correct 49 Time per epoch 0.11074340343475342\n",
            "Epoch  170  loss  0.9802280033170013 correct 50 Time per epoch 0.11117870807647705\n",
            "Epoch  180  loss  0.7189045145327252 correct 50 Time per epoch 0.10961849689483642\n",
            "Epoch  190  loss  1.5098887443018265 correct 50 Time per epoch 0.11025395393371581\n",
            "Epoch  200  loss  0.0014299828378507374 correct 50 Time per epoch 0.1103811502456665\n",
            "Epoch  210  loss  0.2593636990953903 correct 50 Time per epoch 0.14995067119598388\n",
            "Epoch  220  loss  0.8668796820361435 correct 50 Time per epoch 0.189056134223938\n",
            "Epoch  230  loss  0.20065615357066824 correct 49 Time per epoch 0.11216158866882324\n",
            "Epoch  240  loss  0.9751354778464866 correct 50 Time per epoch 0.10978918075561524\n",
            "Epoch  250  loss  0.051120279881150726 correct 50 Time per epoch 0.11131904125213624\n",
            "Epoch  260  loss  0.0297672604690793 correct 50 Time per epoch 0.11813881397247314\n",
            "Epoch  270  loss  1.0504312831647271 correct 49 Time per epoch 0.10984952449798584\n",
            "Epoch  280  loss  0.4809041622152252 correct 50 Time per epoch 0.10946667194366455\n",
            "Epoch  290  loss  0.19378936222149476 correct 50 Time per epoch 0.11000027656555175\n",
            "Epoch  300  loss  0.22538555097529747 correct 50 Time per epoch 0.11441235542297364\n",
            "Epoch  310  loss  1.308985161962895 correct 49 Time per epoch 0.1533799171447754\n",
            "Epoch  320  loss  0.0125820090077368 correct 50 Time per epoch 0.1890047788619995\n",
            "Epoch  330  loss  0.4738793137849225 correct 50 Time per epoch 0.10994317531585693\n",
            "Epoch  340  loss  0.33605274138434077 correct 50 Time per epoch 0.11056420803070069\n",
            "Epoch  350  loss  0.3870854307952717 correct 50 Time per epoch 0.10993781089782714\n",
            "Epoch  360  loss  1.0214881093035832 correct 49 Time per epoch 0.11386642456054688\n",
            "Epoch  370  loss  0.13447224321815573 correct 50 Time per epoch 0.1100649356842041\n",
            "Epoch  380  loss  0.8415821865544987 correct 50 Time per epoch 0.11104109287261962\n",
            "Epoch  390  loss  0.2991686170031502 correct 50 Time per epoch 0.1113133430480957\n",
            "Epoch  400  loss  0.025445227397062037 correct 49 Time per epoch 0.10999495983123779\n",
            "Epoch  410  loss  0.4636795495992929 correct 50 Time per epoch 0.1456385850906372\n",
            "Epoch  420  loss  0.28358573345547494 correct 50 Time per epoch 0.1933736801147461\n",
            "Epoch  430  loss  0.31946395312499154 correct 50 Time per epoch 0.10944614410400391\n",
            "Epoch  440  loss  0.08558653286112176 correct 50 Time per epoch 0.1090163230895996\n",
            "Epoch  450  loss  0.2065363939060571 correct 50 Time per epoch 0.108502197265625\n",
            "Epoch  460  loss  0.06460771672402452 correct 50 Time per epoch 0.11180846691131592\n",
            "Epoch  470  loss  0.5052649667243666 correct 50 Time per epoch 0.1108548402786255\n",
            "Epoch  480  loss  0.1963802396358422 correct 50 Time per epoch 0.11024737358093262\n",
            "Epoch  490  loss  0.28835663129626127 correct 50 Time per epoch 0.1095313310623169\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 100 --DATASET simple --RATE 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBT4PecDtQS3",
        "outputId": "defdb203-ca6a-495c-ff48-1470f97ff11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 100 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Epoch  0  loss  7.357198650204386 correct 38 Time per epoch 0.4482653856277466\n",
            "Epoch  10  loss  4.98915897964179 correct 45 Time per epoch 1.5824486494064331\n",
            "Epoch  20  loss  2.1976805743230505 correct 46 Time per epoch 1.5897902011871339\n",
            "Epoch  30  loss  2.9004835676412393 correct 45 Time per epoch 1.6372377634048463\n",
            "Epoch  40  loss  3.251250887754409 correct 47 Time per epoch 1.5820262908935547\n",
            "Epoch  50  loss  1.4796033739767882 correct 46 Time per epoch 1.5812280178070068\n",
            "Epoch  60  loss  4.639377154234314 correct 46 Time per epoch 1.6576990842819215\n",
            "Epoch  70  loss  2.078155600936099 correct 47 Time per epoch 1.5703636407852173\n",
            "Epoch  80  loss  1.5316967925777674 correct 48 Time per epoch 1.5811646938323975\n",
            "Epoch  90  loss  0.5446958954844076 correct 48 Time per epoch 1.6475631952285767\n",
            "Epoch  100  loss  2.449873778870412 correct 47 Time per epoch 1.590339970588684\n",
            "Epoch  110  loss  0.38874546992140546 correct 48 Time per epoch 1.5709888696670533\n",
            "Epoch  120  loss  1.7194360639369466 correct 49 Time per epoch 1.5945136070251464\n",
            "Epoch  130  loss  1.8249991870734452 correct 49 Time per epoch 1.636206293106079\n",
            "Epoch  140  loss  0.5861702383672712 correct 48 Time per epoch 1.6637208700180053\n",
            "Epoch  150  loss  0.3929063224952324 correct 49 Time per epoch 1.570684552192688\n",
            "Epoch  160  loss  2.1724459667772043 correct 48 Time per epoch 1.6559552669525146\n",
            "Epoch  170  loss  0.47417269001601015 correct 49 Time per epoch 1.579501748085022\n",
            "Epoch  180  loss  1.5813246868671698 correct 49 Time per epoch 1.5714139223098755\n",
            "Epoch  190  loss  1.2426094233540756 correct 49 Time per epoch 1.6513227462768554\n",
            "Epoch  200  loss  1.739378840943092 correct 49 Time per epoch 1.5774714469909668\n",
            "Epoch  210  loss  2.439928648114148 correct 49 Time per epoch 1.576958131790161\n",
            "Epoch  220  loss  0.603007004008531 correct 50 Time per epoch 1.5986249685287475\n",
            "Epoch  230  loss  1.1203620081816774 correct 49 Time per epoch 1.6287386178970338\n",
            "Epoch  240  loss  0.627594984812291 correct 49 Time per epoch 1.5701635837554933\n",
            "Epoch  250  loss  0.9752555552534153 correct 50 Time per epoch 1.5766926288604737\n",
            "Epoch  260  loss  0.31317071211636416 correct 50 Time per epoch 1.6579359769821167\n",
            "Epoch  270  loss  0.5065025871551336 correct 49 Time per epoch 1.5747862815856934\n",
            "Epoch  280  loss  0.7243142947917529 correct 50 Time per epoch 1.5748349666595458\n",
            "Epoch  290  loss  0.9050876533395467 correct 49 Time per epoch 1.6506150722503663\n",
            "Epoch  300  loss  0.519815417007563 correct 49 Time per epoch 1.592959475517273\n",
            "Epoch  310  loss  1.704718279594221 correct 50 Time per epoch 1.5740541458129882\n",
            "Epoch  320  loss  0.7543478790454056 correct 49 Time per epoch 1.5653656721115112\n",
            "Epoch  330  loss  0.19069303999732004 correct 50 Time per epoch 1.6585341691970825\n",
            "Epoch  340  loss  0.991318715116128 correct 50 Time per epoch 1.6590985298156737\n",
            "Epoch  350  loss  1.2631215955057693 correct 50 Time per epoch 1.5746696710586547\n",
            "Epoch  360  loss  0.6695773459732339 correct 49 Time per epoch 1.6562577486038208\n",
            "Epoch  370  loss  0.2527241426419322 correct 49 Time per epoch 1.5721393346786499\n",
            "Epoch  380  loss  0.43344854133060023 correct 49 Time per epoch 1.5791359901428224\n",
            "Epoch  390  loss  0.10489459731722195 correct 50 Time per epoch 1.650852632522583\n",
            "Epoch  400  loss  0.10007497312113778 correct 49 Time per epoch 1.5767351388931274\n",
            "Epoch  410  loss  1.3404430869320194 correct 50 Time per epoch 1.5691748142242432\n",
            "Epoch  420  loss  0.41423757348346174 correct 50 Time per epoch 1.5768578767776489\n",
            "Epoch  430  loss  0.6058951313524595 correct 50 Time per epoch 1.6487502336502076\n",
            "Epoch  440  loss  0.9870924226237183 correct 49 Time per epoch 1.5709683418273925\n",
            "Epoch  450  loss  0.03946025383127734 correct 49 Time per epoch 1.5713172435760498\n",
            "Epoch  460  loss  0.23711322278759045 correct 50 Time per epoch 1.6708690404891968\n",
            "Epoch  470  loss  0.101533323597164 correct 50 Time per epoch 1.5742628812789916\n",
            "Epoch  480  loss  0.8063855624185929 correct 50 Time per epoch 1.5875962972640991\n",
            "Epoch  490  loss  0.04363320153761432 correct 50 Time per epoch 1.6209076166152954\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 100 --DATASET xor --RATE 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5UX_f85tWSL",
        "outputId": "219e0026-2f22-430e-a807-ebf131ec1cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0  loss  6.528275023369353 correct 22 Time per epoch 1.4627237558364867\n",
            "Epoch  10  loss  4.2877176883964925 correct 47 Time per epoch 0.1110661506652832\n",
            "Epoch  20  loss  4.324374417950544 correct 41 Time per epoch 0.11166291236877442\n",
            "Epoch  30  loss  1.7118092404117968 correct 49 Time per epoch 0.11279699802398682\n",
            "Epoch  40  loss  2.050872327632735 correct 49 Time per epoch 0.11217312812805176\n",
            "Epoch  50  loss  1.597773911418098 correct 46 Time per epoch 0.11132428646087647\n",
            "Epoch  60  loss  1.9819400698609726 correct 49 Time per epoch 0.11056866645812988\n",
            "Epoch  70  loss  1.639872900228014 correct 49 Time per epoch 0.11049323081970215\n",
            "Epoch  80  loss  1.181799442978592 correct 49 Time per epoch 0.11202948093414307\n",
            "Epoch  90  loss  1.8767653337925143 correct 49 Time per epoch 0.17596683502197266\n",
            "Epoch  100  loss  0.8371002718860567 correct 49 Time per epoch 0.16111915111541747\n",
            "Epoch  110  loss  0.39023110316073695 correct 50 Time per epoch 0.11271145343780517\n",
            "Epoch  120  loss  0.45715818298824334 correct 49 Time per epoch 0.11169359683990479\n",
            "Epoch  130  loss  1.2340055267279115 correct 50 Time per epoch 0.1110102653503418\n",
            "Epoch  140  loss  0.6103370302286064 correct 50 Time per epoch 0.11323065757751465\n",
            "Epoch  150  loss  1.0901422392690718 correct 50 Time per epoch 0.1114161491394043\n",
            "Epoch  160  loss  0.12445051759086685 correct 49 Time per epoch 0.11085991859436035\n",
            "Epoch  170  loss  0.31381787922736165 correct 50 Time per epoch 0.1123319149017334\n",
            "Epoch  180  loss  0.18691340994488548 correct 50 Time per epoch 0.19444496631622316\n",
            "Epoch  190  loss  0.2447200281343434 correct 50 Time per epoch 0.24259014129638673\n",
            "Epoch  200  loss  0.8053217984854636 correct 50 Time per epoch 0.13876669406890868\n",
            "Epoch  210  loss  0.3099817587087687 correct 50 Time per epoch 0.11080949306488037\n",
            "Epoch  220  loss  1.4113461682469302 correct 50 Time per epoch 0.11123373508453369\n",
            "Epoch  230  loss  0.969516500547963 correct 50 Time per epoch 0.11069614887237549\n",
            "Epoch  240  loss  0.06718547249129793 correct 49 Time per epoch 0.11010541915893554\n",
            "Epoch  250  loss  0.3744387949657912 correct 50 Time per epoch 0.11114580631256103\n",
            "Epoch  260  loss  0.5080310573217296 correct 50 Time per epoch 0.11961197853088379\n",
            "Epoch  270  loss  1.1513708577501705 correct 50 Time per epoch 0.11292452812194824\n",
            "Epoch  280  loss  0.2699568395408089 correct 50 Time per epoch 0.11033556461334229\n",
            "Epoch  290  loss  0.23776245380586208 correct 50 Time per epoch 0.2011582851409912\n",
            "Epoch  300  loss  0.0746719955093508 correct 49 Time per epoch 0.13878445625305175\n",
            "Epoch  310  loss  0.5396445128543039 correct 50 Time per epoch 0.11117193698883057\n",
            "Epoch  320  loss  0.8533089801582873 correct 50 Time per epoch 0.11038179397583008\n",
            "Epoch  330  loss  1.024858339924342 correct 50 Time per epoch 0.11232957839965821\n",
            "Epoch  340  loss  0.18230641260539254 correct 50 Time per epoch 0.1115645170211792\n",
            "Epoch  350  loss  0.5712081763650627 correct 50 Time per epoch 0.11272530555725098\n",
            "Epoch  360  loss  0.6360743500983793 correct 50 Time per epoch 0.11066064834594727\n",
            "Epoch  370  loss  0.16007146144615675 correct 50 Time per epoch 0.10993049144744874\n",
            "Epoch  380  loss  0.22985502798455046 correct 50 Time per epoch 0.10964956283569335\n",
            "Epoch  390  loss  0.33808866647660585 correct 50 Time per epoch 0.18424456119537352\n",
            "Epoch  400  loss  0.19664080338214357 correct 50 Time per epoch 0.15303208827972412\n",
            "Epoch  410  loss  0.5527057703255501 correct 50 Time per epoch 0.10928518772125244\n",
            "Epoch  420  loss  0.02455244434635427 correct 50 Time per epoch 0.1106644868850708\n",
            "Epoch  430  loss  0.4495345732781258 correct 50 Time per epoch 0.11852936744689942\n",
            "Epoch  440  loss  0.45632758259547196 correct 50 Time per epoch 0.11136507987976074\n",
            "Epoch  450  loss  0.10386197237110838 correct 50 Time per epoch 0.11001877784729004\n",
            "Epoch  460  loss  0.4457662423588716 correct 50 Time per epoch 0.11058964729309081\n",
            "Epoch  470  loss  0.08569770107300596 correct 50 Time per epoch 0.11004478931427002\n",
            "Epoch  480  loss  0.30173596987494317 correct 50 Time per epoch 0.11073358058929443\n",
            "Epoch  490  loss  0.1881854680537514 correct 50 Time per epoch 0.1792076826095581\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 100 --DATASET xor --RATE 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rMU9KaN18iVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b75686a-f30a-42b2-b391-eca63721ac03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 13 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 13 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 63 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 63 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 63 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 49 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 13 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 14 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Epoch  0  loss  7.000360093429833 correct 43 Time per epoch 0.3491117000579834\n",
            "Epoch  10  loss  3.775766526274423 correct 43 Time per epoch 1.6753533601760864\n",
            "Epoch  20  loss  0.4885228371957832 correct 45 Time per epoch 1.729252004623413\n",
            "Epoch  30  loss  0.4872548281381251 correct 50 Time per epoch 1.6713150024414063\n",
            "Epoch  40  loss  0.9365585218427813 correct 50 Time per epoch 1.757141351699829\n",
            "Epoch  50  loss  0.8800666177591823 correct 50 Time per epoch 1.658739948272705\n",
            "Epoch  60  loss  1.2337028794483187 correct 50 Time per epoch 1.6615067005157471\n",
            "Epoch  70  loss  0.9998951260407065 correct 50 Time per epoch 1.739526915550232\n",
            "Epoch  80  loss  0.6160068508465498 correct 50 Time per epoch 1.6656420946121215\n",
            "Epoch  90  loss  0.14959700058122263 correct 48 Time per epoch 1.6556017637252807\n",
            "Epoch  100  loss  0.9650618103263872 correct 49 Time per epoch 1.7389044523239137\n",
            "Epoch  110  loss  1.0009910986218675 correct 50 Time per epoch 1.6674356698989867\n",
            "Epoch  120  loss  0.001862541799106978 correct 46 Time per epoch 1.7281122922897338\n",
            "Epoch  130  loss  0.6105513975878184 correct 47 Time per epoch 1.6667046785354613\n",
            "Epoch  140  loss  1.2342749221129032 correct 48 Time per epoch 1.6610356330871583\n",
            "Epoch  150  loss  0.3115650682857444 correct 49 Time per epoch 1.7372191905975343\n",
            "Epoch  160  loss  1.0192190028056882 correct 50 Time per epoch 1.7474852323532104\n",
            "Epoch  170  loss  0.7488148680971483 correct 50 Time per epoch 1.6661609172821046\n",
            "Epoch  180  loss  0.34162930515686135 correct 50 Time per epoch 1.73691885471344\n",
            "Epoch  190  loss  0.5085624737347073 correct 50 Time per epoch 1.654402995109558\n",
            "Epoch  200  loss  0.35635743233124584 correct 50 Time per epoch 1.6527538299560547\n",
            "Epoch  210  loss  0.0027412447387808723 correct 49 Time per epoch 1.7380970478057862\n",
            "Epoch  220  loss  0.5110860491183777 correct 50 Time per epoch 1.648557996749878\n",
            "Epoch  230  loss  0.6135522204946149 correct 50 Time per epoch 1.7002411842346192\n",
            "Epoch  240  loss  0.41265953848899467 correct 50 Time per epoch 1.6890200138092042\n",
            "Epoch  250  loss  0.727802792051781 correct 50 Time per epoch 1.6535060405731201\n",
            "Epoch  260  loss  0.291619919556552 correct 50 Time per epoch 1.7456716060638429\n",
            "Epoch  270  loss  0.9377083411695825 correct 49 Time per epoch 1.6549450397491454\n",
            "Epoch  280  loss  0.07503656665791832 correct 50 Time per epoch 1.653823971748352\n",
            "Epoch  290  loss  0.606209333043264 correct 50 Time per epoch 1.7398022890090943\n",
            "Epoch  300  loss  0.005712076748624993 correct 50 Time per epoch 1.6587799787521362\n",
            "Epoch  310  loss  1.305381885987269 correct 50 Time per epoch 1.663024640083313\n",
            "Epoch  320  loss  7.262454332217169e-05 correct 50 Time per epoch 1.7148625373840332\n",
            "Epoch  330  loss  0.2859040339943481 correct 50 Time per epoch 1.6576553106307983\n",
            "Epoch  340  loss  0.44132882067538715 correct 50 Time per epoch 1.7245872259140014\n",
            "Epoch  350  loss  0.000583242454226611 correct 50 Time per epoch 1.746854591369629\n",
            "Epoch  360  loss  0.22734204775246558 correct 50 Time per epoch 1.645559597015381\n",
            "Epoch  370  loss  0.5344641971716934 correct 49 Time per epoch 1.7346656560897826\n",
            "Epoch  380  loss  0.4915285364830179 correct 50 Time per epoch 1.655346941947937\n",
            "Epoch  390  loss  6.512264483145665e-05 correct 50 Time per epoch 1.674775528907776\n",
            "Epoch  400  loss  0.003437713065598624 correct 50 Time per epoch 1.7150470972061158\n",
            "Epoch  410  loss  0.21421540051874122 correct 50 Time per epoch 1.6459196567535401\n",
            "Epoch  420  loss  0.2587896740875578 correct 50 Time per epoch 1.723518395423889\n",
            "Epoch  430  loss  0.001360230277267349 correct 47 Time per epoch 1.6692610263824463\n",
            "Epoch  440  loss  0.06037201859554331 correct 50 Time per epoch 1.6503085374832154\n",
            "Epoch  450  loss  0.0007078390972143175 correct 50 Time per epoch 1.7316558837890625\n",
            "Epoch  460  loss  0.07356948128335573 correct 50 Time per epoch 1.6542655944824218\n",
            "Epoch  470  loss  1.1509354033448206e-05 correct 50 Time per epoch 1.664808988571167\n",
            "Epoch  480  loss  0.31382458454050094 correct 50 Time per epoch 1.7450776100158691\n",
            "Epoch  490  loss  1.0406085233200262 correct 50 Time per epoch 1.6513777494430542\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 200 --DATASET simple --RATE 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0a7sti9Dy7Vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830058eb-b1bc-41e2-99a5-ea3cbcb576ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0  loss  2.0323814824257833 correct 46 Time per epoch 1.4579288244247437\n",
            "Epoch  10  loss  0.34575115264416956 correct 49 Time per epoch 0.3570537567138672\n",
            "Epoch  20  loss  1.102252699682478 correct 49 Time per epoch 0.2724740982055664\n",
            "Epoch  30  loss  0.443838788253701 correct 50 Time per epoch 0.26042296886444094\n",
            "Epoch  40  loss  0.10342929093624108 correct 50 Time per epoch 0.2583003520965576\n",
            "Epoch  50  loss  0.9342391505405047 correct 50 Time per epoch 0.27146153450012206\n",
            "Epoch  60  loss  1.471104926292973 correct 50 Time per epoch 0.3571170330047607\n",
            "Epoch  70  loss  0.3598319667980328 correct 50 Time per epoch 0.2631401777267456\n",
            "Epoch  80  loss  0.1469966358469223 correct 50 Time per epoch 0.37769064903259275\n",
            "Epoch  90  loss  0.37804712288405734 correct 50 Time per epoch 0.3115377902984619\n",
            "Epoch  100  loss  0.03790966254360692 correct 50 Time per epoch 0.3153393268585205\n",
            "Epoch  110  loss  0.8547582488087573 correct 50 Time per epoch 0.25612964630126955\n",
            "Epoch  120  loss  0.08934128960002835 correct 50 Time per epoch 0.258467698097229\n",
            "Epoch  130  loss  0.06821811041644725 correct 50 Time per epoch 0.2587639570236206\n",
            "Epoch  140  loss  0.04257361647084147 correct 50 Time per epoch 0.37181222438812256\n",
            "Epoch  150  loss  0.5684944903933333 correct 50 Time per epoch 0.25813376903533936\n",
            "Epoch  160  loss  0.3845847617564051 correct 50 Time per epoch 0.2569802522659302\n",
            "Epoch  170  loss  0.017972094190366234 correct 50 Time per epoch 0.2622771978378296\n",
            "Epoch  180  loss  0.35939495067711097 correct 50 Time per epoch 0.37165882587432864\n",
            "Epoch  190  loss  0.5554534043878767 correct 50 Time per epoch 0.2573284864425659\n",
            "Epoch  200  loss  0.12310127484553898 correct 50 Time per epoch 0.2555901050567627\n",
            "Epoch  210  loss  0.0398237935775945 correct 50 Time per epoch 0.2555456876754761\n",
            "Epoch  220  loss  0.010914764197801708 correct 50 Time per epoch 0.29503955841064455\n",
            "Epoch  230  loss  0.03945617353655968 correct 50 Time per epoch 0.3365968942642212\n",
            "Epoch  240  loss  0.08271958762773494 correct 50 Time per epoch 0.2576359510421753\n",
            "Epoch  250  loss  0.34690382100577793 correct 50 Time per epoch 0.2565868616104126\n",
            "Epoch  260  loss  0.011445607681785172 correct 50 Time per epoch 0.2640532493591309\n",
            "Epoch  270  loss  0.3506395617528238 correct 50 Time per epoch 0.36884050369262694\n",
            "Epoch  280  loss  0.08424174108383144 correct 50 Time per epoch 0.26000959873199464\n",
            "Epoch  290  loss  0.002447075990270569 correct 50 Time per epoch 0.2545535802841187\n",
            "Epoch  300  loss  0.0076666266775685665 correct 50 Time per epoch 0.2555701732635498\n",
            "Epoch  310  loss  0.32062409828833444 correct 50 Time per epoch 0.3596575975418091\n",
            "Epoch  320  loss  0.09448048493864822 correct 50 Time per epoch 0.2650566577911377\n",
            "Epoch  330  loss  0.4060436270288088 correct 50 Time per epoch 0.2548715591430664\n",
            "Epoch  340  loss  0.2770055559264609 correct 50 Time per epoch 0.255192494392395\n",
            "Epoch  350  loss  0.3753169086878286 correct 50 Time per epoch 0.2688390493392944\n",
            "Epoch  360  loss  0.07837431100481666 correct 50 Time per epoch 0.3532301664352417\n",
            "Epoch  370  loss  0.010608165536730843 correct 50 Time per epoch 0.2562769651412964\n",
            "Epoch  380  loss  0.26798849908942096 correct 50 Time per epoch 0.2591264247894287\n",
            "Epoch  390  loss  0.2784278162165263 correct 50 Time per epoch 0.25400404930114745\n",
            "Epoch  400  loss  0.0586052932419302 correct 50 Time per epoch 0.37382590770721436\n",
            "Epoch  410  loss  0.0008723194020494614 correct 50 Time per epoch 0.2584576368331909\n",
            "Epoch  420  loss  0.2586216320384123 correct 50 Time per epoch 0.25503220558166506\n",
            "Epoch  430  loss  0.06051031530336377 correct 50 Time per epoch 0.2555375576019287\n",
            "Epoch  440  loss  0.19242953567494075 correct 50 Time per epoch 0.32076098918914797\n",
            "Epoch  450  loss  2.4822851854637323e-05 correct 50 Time per epoch 0.3047224521636963\n",
            "Epoch  460  loss  0.010551584028711881 correct 50 Time per epoch 0.2558619499206543\n",
            "Epoch  470  loss  0.3453719328026343 correct 50 Time per epoch 0.2549257755279541\n",
            "Epoch  480  loss  0.06445386826421769 correct 50 Time per epoch 0.25376651287078855\n",
            "Epoch  490  loss  0.06494521617249414 correct 50 Time per epoch 0.3757734775543213\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 200 --DATASET simple --RATE 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc2Djm7ty89u"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}