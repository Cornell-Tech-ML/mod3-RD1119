{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4pWhxZCyMQ-"
   },
   "source": [
    "# How to run on GPU\n",
    "\n",
    "Step 1) Go to https://github.com/settings/tokens and get a token that can read your private repos\n",
    "\n",
    "Step 2) Clone this colab notebook and change the execution environment to GPU.\n",
    "\n",
    "Step 3) Install python 3.8\n",
    "\n",
    "Step 4) Clone and install your code.\n",
    "\n",
    "Step 5) Run the command-line code for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTzMYZB5yynZ"
   },
   "source": [
    "## Step 3: Install python 3.8\n",
    "Run the cell below without editing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lciKNd6myIjl",
    "outputId": "979090cd-34b1-44b3-fd4a-8ab0177c16f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
      "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
      "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "python3.12 is already the newest version (3.12.7-1+jammy1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 65 not upgraded.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2222k  100 2222k    0     0  12.0M      0 --:--:-- --:--:-- --:--:-- 12.0M\n",
      "Collecting pip\n",
      "  Using cached pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.3.1\n",
      "    Uninstalling pip-24.3.1:\n",
      "      Successfully uninstalled pip-24.3.1\n",
      "Successfully installed pip-24.3.1\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update -y\n",
    "!sudo apt-get install python3.12\n",
    "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
    "!python3.12 get-pip.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guhMlPoey3zE"
   },
   "source": [
    "## Step 4: Clone and install your code\n",
    "First we need to set some environment variables. Get your github API token and MLE repo username and put them into the below variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmmAQK12zJJP",
    "outputId": "296c2742-a52e-4519-f366-eea45ef90cea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKEN=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\n",
      "env: USER=RD1119\n"
     ]
    }
   ],
   "source": [
    "%env TOKEN=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\n",
    "%env USER=RD1119"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JZt2xZwzS2b"
   },
   "source": [
    "Run the below code. Editing should not be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYb6KtYFzJjD",
    "outputId": "0bb877fa-0bef-489e-916f-af393459a8fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DIR=mod3-RD1119\n",
      "https://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@github.com/Cornell-Tech-ML/mod3-RD1119\n",
      "fatal: destination path 'mod3-RD1119' already exists and is not an empty directory.\n",
      "Requirement already satisfied: colorama==0.4.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (0.4.3)\n",
      "Requirement already satisfied: hypothesis==6.54 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (6.54.0)\n",
      "Requirement already satisfied: numba==0.60 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.60.0)\n",
      "Requirement already satisfied: numpy==2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: pre-commit==2.20.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.20.0)\n",
      "Requirement already satisfied: pytest==8.3.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (8.3.2)\n",
      "Requirement already satisfied: pytest-env in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (1.1.4)\n",
      "Requirement already satisfied: pytest-runner==5.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (5.2)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (4.12.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from hypothesis==6.54->-r requirements.txt (line 2)) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from hypothesis==6.54->-r requirements.txt (line 2)) (2.4.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.60->-r requirements.txt (line 3)) (0.43.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pre-commit==2.20.0->-r requirements.txt (line 5)) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pre-commit==2.20.0->-r requirements.txt (line 5)) (2.6.2)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.12/dist-packages (from pre-commit==2.20.0->-r requirements.txt (line 5)) (1.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from pre-commit==2.20.0->-r requirements.txt (line 5)) (6.0.2)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from pre-commit==2.20.0->-r requirements.txt (line 5)) (0.10.2)\n",
      "Requirement already satisfied: virtualenv>=20.0.8 in /usr/local/lib/python3.12/dist-packages (from pre-commit==2.20.0->-r requirements.txt (line 5)) (20.27.1)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.12/dist-packages (from pytest==8.3.2->-r requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pytest==8.3.2->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest==8.3.2->-r requirements.txt (line 6)) (1.5.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.12/dist-packages (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 5)) (0.3.9)\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.12/dist-packages (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 5)) (3.16.1)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 5)) (4.3.6)\n",
      "Requirement already satisfied: altair==4.2.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.extra.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: datasets==2.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.extra.txt (line 2)) (2.4.0)\n",
      "Requirement already satisfied: embeddings==0.0.8 in /usr/local/lib/python3.12/dist-packages (from -r requirements.extra.txt (line 3)) (0.0.8)\n",
      "Requirement already satisfied: networkx==3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.extra.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: plotly==4.14.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.extra.txt (line 5)) (4.14.3)\n",
      "Requirement already satisfied: pydot==1.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.extra.txt (line 6)) (1.4.1)\n",
      "Requirement already satisfied: python-mnist in /usr/local/lib/python3.12/dist-packages (from -r requirements.extra.txt (line 7)) (0.7)\n",
      "Requirement already satisfied: streamlit==1.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.extra.txt (line 8)) (1.12.0)\n",
      "Requirement already satisfied: streamlit-ace in /usr/local/lib/python3.12/dist-packages (from -r requirements.extra.txt (line 9)) (0.1.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.extra.txt (line 10)) (2.5.1)\n",
      "Requirement already satisfied: watchdog==1.0.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.extra.txt (line 11)) (1.0.2)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from altair==4.2.2->-r requirements.extra.txt (line 1)) (0.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair==4.2.2->-r requirements.extra.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair==4.2.2->-r requirements.extra.txt (line 1)) (4.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from altair==4.2.2->-r requirements.extra.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.12/dist-packages (from altair==4.2.2->-r requirements.extra.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.12/dist-packages (from altair==4.2.2->-r requirements.extra.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.12/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (0.3.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (4.67.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (0.70.13)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.11.1->datasets==2.4.0->-r requirements.extra.txt (line 2)) (2024.10.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (3.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (0.26.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.12/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (0.18.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from plotly==4.14.3->-r requirements.extra.txt (line 5)) (1.3.4)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from plotly==4.14.3->-r requirements.extra.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/lib/python3/dist-packages (from pydot==1.4.1->-r requirements.extra.txt (line 6)) (2.4.7)\n",
      "Requirement already satisfied: blinker>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (1.4)\n",
      "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (5.5.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /usr/lib/python3/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (4.6.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (11.0.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (3.20.3)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (0.9.1)\n",
      "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (1.1)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (2.9.0.post0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (13.9.4)\n",
      "Requirement already satisfied: semver in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (3.0.2)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (0.10.2)\n",
      "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (6.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (4.12.2)\n",
      "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (5.2)\n",
      "Requirement already satisfied: validators>=0.2 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (0.34.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (3.1.43)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (75.5.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.extra.txt (line 10)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch->-r requirements.extra.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (1.17.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19->streamlit==1.12.0->-r requirements.extra.txt (line 8)) (4.0.11)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.4.0->-r requirements.extra.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.extra.txt (line 1)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.extra.txt (line 1)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.extra.txt (line 1)) (0.21.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.extra.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.extra.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair==4.2.2->-r requirements.extra.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 2)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 2)) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 8)) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.12.0->-r requirements.extra.txt (line 8)) (5.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 8)) (0.1.2)\n",
      "Processing /content/mod3-RD1119\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: minitorch\n",
      "  Building wheel for minitorch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for minitorch: filename=minitorch-0.5-py2.py3-none-any.whl size=31615 sha256=6d42a31106d3d6fa2e2b865714d8813dbb24a6f57753dc0c00866fcb820fbc4f\n",
      "  Stored in directory: /root/.cache/pip/wheels/a8/bd/65/62807f26aa8f5d5247cf72202e3c2b0a35f528b053d1cc358c\n",
      "Successfully built minitorch\n",
      "Installing collected packages: minitorch\n",
      "  Attempting uninstall: minitorch\n",
      "    Found existing installation: minitorch 0.5\n",
      "    Uninstalling minitorch-0.5:\n",
      "      Successfully uninstalled minitorch-0.5\n",
      "Successfully installed minitorch-0.5\n"
     ]
    }
   ],
   "source": [
    "TOKEN = %env TOKEN\n",
    "USER = %env USER\n",
    "# %env DIR=mle-module-3-$USER\n",
    "%env DIR=mod3-$USER\n",
    "DIR = %env DIR\n",
    "\n",
    "!echo https://$TOKEN@github.com/Cornell-Tech-ML/$DIR\n",
    "\n",
    "!git clone -b master --single-branch https://$TOKEN@github.com/Cornell-Tech-ML/$DIR\n",
    "!cd $DIR; pip3.12 install -r requirements.txt; pip3.12 install -r requirements.extra.txt; pip3.12 install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2xn5AhUzaW_"
   },
   "source": [
    "If you update your code, you can re-pull the repo by running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GywpmTnozf26",
    "outputId": "d2a0e070-c39b-46b0-d453-fa59d5f0c8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From https://github.com/Cornell-Tech-ML/mod3-RD1119\n",
      " * branch            master     -> FETCH_HEAD\n",
      "Already up to date.\n",
      "Processing /content/mod3-RD1119\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: minitorch\n",
      "  Building wheel for minitorch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for minitorch: filename=minitorch-0.5-py2.py3-none-any.whl size=31615 sha256=6d42a31106d3d6fa2e2b865714d8813dbb24a6f57753dc0c00866fcb820fbc4f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s5_wgtij/wheels/a8/bd/65/62807f26aa8f5d5247cf72202e3c2b0a35f528b053d1cc358c\n",
      "Successfully built minitorch\n",
      "Installing collected packages: minitorch\n",
      "  Attempting uninstall: minitorch\n",
      "    Found existing installation: minitorch 0.5\n",
      "    Uninstalling minitorch-0.5:\n",
      "      Successfully uninstalled minitorch-0.5\n",
      "Successfully installed minitorch-0.5\n"
     ]
    }
   ],
   "source": [
    "!cd $DIR; git pull origin master; pip3.12 install --force-reinstall --no-cache-dir ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJI2w775POnx"
   },
   "source": [
    "Run Pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9GsVaqr8wlg",
    "outputId": "9abdfef1-361f-43bd-ac3b-9cd338b66d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "platform linux -- Python 3.12.7, pytest-8.3.2, pluggy-1.5.0\n",
      "rootdir: /content/mod3-RD1119\n",
      "configfile: pyproject.toml\n",
      "plugins: hypothesis-6.54.0, env-1.1.4\n",
      "collected 117 items                                                                                \u001b[0m\n",
      "\n",
      "tests/test_tensor_general.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m [ 53%]\n",
      "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                       [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m========================================= warnings summary =========================================\u001b[0m\n",
      "tests/test_tensor_general.py: 20 warnings\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py: 4377 warnings\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py: 12 warnings\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_one_args[cuda-fn2]\n",
      "tests/test_tensor_general.py::test_one_args[cuda-fn10]\n",
      "tests/test_tensor_general.py::test_two_args[cuda-fn1]\n",
      "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
      "tests/test_tensor_general.py::test_one_derivative[cuda-fn2]\n",
      "tests/test_tensor_general.py::test_two_grad[cuda-fn3]\n",
      "tests/test_tensor_general.py::test_sum_practice2\n",
      "tests/test_tensor_general.py::test_bmm[cuda]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 3 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
      "tests/test_tensor_general.py::test_bmm[cuda]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 6 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 9 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
      "tests/test_tensor_general.py::test_mul_practice5\n",
      "tests/test_tensor_general.py::test_bmm[cuda]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
      "tests/test_tensor_general.py::test_mul_practice4\n",
      "tests/test_tensor_general.py::test_bmm[cuda]\n",
      "tests/test_tensor_general.py::test_bmm[cuda]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 12 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_one_derivative[cuda-fn1]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 18 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_two_grad[cuda-fn1]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 27 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_sum_practice_other_dims\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_mul_practice4\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 35 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_bmm[cuda]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 5 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_bmm[cuda]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 48 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_bmm[cuda]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 36 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_bmm[cuda]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 24 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_bmm[cuda]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 64 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_tensor_general.py::test_bmm[cuda]\n",
      "  /usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m========================== \u001b[32m117 passed\u001b[0m, \u001b[33m\u001b[1m4438 warnings\u001b[0m\u001b[33m in 293.33s (0:04:53)\u001b[0m\u001b[33m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd $DIR; PYTHONPATH=/content/$DIR pytest tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8xgNdYkPWN5"
   },
   "source": [
    "Run Timing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pj62tthe_B60",
    "outputId": "8b7304c5-e599-4e5a-d991-15113341b058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 2 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Running size 64\n",
      "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 8 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "{'fast': 0.023119529088338215, 'gpu': 0.023346821467081707}\n",
      "Running size 128\n",
      "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 32 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "{'fast': 0.057913780212402344, 'gpu': 0.04448699951171875}\n",
      "Running size 256\n",
      "{'fast': 0.30489015579223633, 'gpu': 0.18598063786824545}\n",
      "Running size 512\n",
      "{'fast': 1.1299574375152588, 'gpu': 0.2293673356374105}\n",
      "Running size 1024\n",
      "{'fast': 9.404240926106771, 'gpu': 1.033451795578003}\n",
      "\n",
      "Timing summary\n",
      "Size: 64\n",
      "    fast: 0.02312\n",
      "    gpu: 0.02335\n",
      "Size: 128\n",
      "    fast: 0.05791\n",
      "    gpu: 0.04449\n",
      "Size: 256\n",
      "    fast: 0.30489\n",
      "    gpu: 0.18598\n",
      "Size: 512\n",
      "    fast: 1.12996\n",
      "    gpu: 0.22937\n",
      "Size: 1024\n",
      "    fast: 9.40424\n",
      "    gpu: 1.03345\n",
      "Fast_times [0.023119529088338215, 0.057913780212402344, 0.30489015579223633, 1.1299574375152588, 9.404240926106771]\n",
      "gpu_times [0.023346821467081707, 0.04448699951171875, 0.18598063786824545, 0.2293673356374105, 1.033451795578003]\n"
     ]
    }
   ],
   "source": [
    "!cd $DIR; PYTHONPATH=/content/$DIR python3 timing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ewObvX7PbUw"
   },
   "source": [
    "Draw the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "A4wm4Ojt8iDJ",
    "outputId": "868cb4bd-89f1-42d2-b77f-b086e180fa63"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data from the provided results\n",
    "sizes = [64, 128, 256, 512, 1024]  # Sizes of the square matrices\n",
    "fast_times = [\n",
    "    0.023119529088338215,\n",
    "    0.057913780212402344,\n",
    "    0.30489015579223633,\n",
    "    1.1299574375152588,\n",
    "    9.404240926106771,\n",
    "]  # Execution times for FastOps\n",
    "gpu_times = [\n",
    "    0.023346821467081707,\n",
    "    0.04448699951171875,\n",
    "    0.18598063786824545,\n",
    "    0.2293673356374105,\n",
    "    1.033451795578003,\n",
    "]  # Execution times for CudaOps\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sizes, fast_times, label=\"FastOps (Naive Numba JIT)\", marker=\"o\", color=\"blue\")\n",
    "plt.plot(\n",
    "    sizes, gpu_times, label=\"CudaOps (CUDA Implementation)\", marker=\"x\", color=\"red\"\n",
    ")\n",
    "plt.xlabel(\"Matrix Size (n x n)\")\n",
    "plt.ylabel(\"Execution Time (s)\")\n",
    "plt.title(\"Comparison of Matrix Multiplication Execution Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qufLzTGmzs1K"
   },
   "source": [
    "## Step 5: Run the training command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FY8Q4MqEzvGW",
    "outputId": "4bac104e-5cfb-408a-dd54-0d4739a472a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 100 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Epoch  0  loss  7.688148222933304 correct 30 Time per epoch 0.3406862258911133\n",
      "Epoch  10  loss  6.1680151037968205 correct 35 Time per epoch 1.6692253589630126\n",
      "Epoch  20  loss  4.7741392840752965 correct 37 Time per epoch 1.762924313545227\n",
      "Epoch  30  loss  4.346382903389426 correct 40 Time per epoch 1.6808827877044679\n",
      "Epoch  40  loss  4.308503028779119 correct 44 Time per epoch 1.719099497795105\n",
      "Epoch  50  loss  4.197957964156718 correct 42 Time per epoch 1.7342091798782349\n",
      "Epoch  60  loss  2.9995077168207036 correct 45 Time per epoch 1.6808377504348755\n",
      "Epoch  70  loss  3.4779208657886667 correct 46 Time per epoch 1.7483661651611329\n",
      "Epoch  80  loss  3.9497797183263703 correct 48 Time per epoch 1.6790812253952025\n",
      "Epoch  90  loss  3.9307794378358123 correct 46 Time per epoch 1.6695638656616212\n",
      "Epoch  100  loss  2.3408501507309514 correct 49 Time per epoch 1.824935245513916\n",
      "Epoch  110  loss  2.0587853155329743 correct 48 Time per epoch 1.6709300994873046\n",
      "Epoch  120  loss  4.132695305593517 correct 46 Time per epoch 1.7615332841873168\n",
      "Epoch  130  loss  3.454619310193144 correct 50 Time per epoch 1.674421501159668\n",
      "Epoch  140  loss  1.8311892886856576 correct 48 Time per epoch 1.6600759744644165\n",
      "Epoch  150  loss  1.0560337043392742 correct 49 Time per epoch 1.7388724327087401\n",
      "Epoch  160  loss  1.980566183854537 correct 48 Time per epoch 1.667748475074768\n",
      "Epoch  170  loss  1.7985442649207157 correct 49 Time per epoch 1.7507199764251709\n",
      "Epoch  180  loss  0.5399352055832123 correct 47 Time per epoch 1.6556903839111328\n",
      "Epoch  190  loss  1.6947419634122007 correct 50 Time per epoch 1.6585009574890137\n",
      "Epoch  200  loss  0.9725340137803034 correct 48 Time per epoch 1.7355946063995362\n",
      "Epoch  210  loss  1.2648026105825658 correct 47 Time per epoch 1.6688340902328491\n",
      "Epoch  220  loss  0.6692184937686563 correct 48 Time per epoch 1.6789358139038086\n",
      "Epoch  230  loss  0.48010416029548736 correct 49 Time per epoch 1.724643301963806\n",
      "Epoch  240  loss  1.080381112160227 correct 49 Time per epoch 1.6610349655151366\n",
      "Epoch  250  loss  0.4393718342869569 correct 47 Time per epoch 1.7338584423065186\n",
      "Epoch  260  loss  1.1302600183773832 correct 50 Time per epoch 1.6751198053359986\n",
      "Epoch  270  loss  1.2608600825610796 correct 50 Time per epoch 1.7502344131469727\n",
      "Epoch  280  loss  1.4453276193213649 correct 49 Time per epoch 1.7316830635070801\n",
      "Epoch  290  loss  0.952912317426057 correct 49 Time per epoch 1.6306398153305053\n",
      "Epoch  300  loss  0.7348444740058877 correct 50 Time per epoch 1.7147754192352296\n",
      "Epoch  310  loss  0.9970982565364992 correct 50 Time per epoch 1.7062728643417358\n",
      "Epoch  320  loss  1.1312808032704507 correct 50 Time per epoch 1.6513673543930054\n",
      "Epoch  330  loss  0.9106938125691048 correct 49 Time per epoch 1.7412392854690553\n",
      "Epoch  340  loss  0.2432130729158703 correct 49 Time per epoch 1.6508301019668579\n",
      "Epoch  350  loss  1.4321382612744478 correct 48 Time per epoch 1.6689801692962647\n",
      "Epoch  360  loss  1.2770993632872834 correct 48 Time per epoch 1.7349042415618896\n",
      "Epoch  370  loss  0.3905935357692314 correct 49 Time per epoch 1.6653281211853028\n",
      "Epoch  380  loss  0.10067609630348295 correct 50 Time per epoch 1.7467737674713135\n",
      "Epoch  390  loss  0.5296563485765328 correct 49 Time per epoch 1.664874053001404\n",
      "Epoch  400  loss  0.10217826939219532 correct 48 Time per epoch 1.6567391157150269\n",
      "Epoch  410  loss  1.5051979274325107 correct 49 Time per epoch 1.7463252544403076\n",
      "Epoch  420  loss  0.6155442472982214 correct 49 Time per epoch 1.670920157432556\n",
      "Epoch  430  loss  0.14839779512578766 correct 49 Time per epoch 1.712520694732666\n",
      "Epoch  440  loss  0.45083244030075137 correct 50 Time per epoch 1.7555158853530883\n",
      "Epoch  450  loss  0.6071345827957436 correct 48 Time per epoch 1.6565726280212403\n",
      "Epoch  460  loss  0.4478856085316886 correct 49 Time per epoch 1.7316564559936523\n",
      "Epoch  470  loss  1.1203439569826616 correct 45 Time per epoch 1.659480905532837\n",
      "Epoch  480  loss  0.17388449337319056 correct 49 Time per epoch 1.69452645778656\n",
      "Epoch  490  loss  0.8848135997497504 correct 50 Time per epoch 1.7197197437286378\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 100 --DATASET split --RATE 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvzWOWT_tKZQ",
    "outputId": "964e22a0-3094-47ca-fc09-d0469437f8fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  loss  8.760159055029817 correct 22 Time per epoch 1.537349271774292\n",
      "Epoch  10  loss  6.241649899491496 correct 36 Time per epoch 0.18757109642028807\n",
      "Epoch  20  loss  5.548609635617908 correct 42 Time per epoch 0.11908247470855712\n",
      "Epoch  30  loss  6.880766694680443 correct 45 Time per epoch 0.11998693943023682\n",
      "Epoch  40  loss  4.506264573864563 correct 46 Time per epoch 0.11753599643707276\n",
      "Epoch  50  loss  3.712752086351173 correct 48 Time per epoch 0.11840150356292725\n",
      "Epoch  60  loss  2.373912691896443 correct 48 Time per epoch 0.1181708574295044\n",
      "Epoch  70  loss  3.2657258889205116 correct 46 Time per epoch 0.11861536502838135\n",
      "Epoch  80  loss  2.8084246521120333 correct 47 Time per epoch 0.12122879028320313\n",
      "Epoch  90  loss  2.384135625036369 correct 46 Time per epoch 0.11840715408325195\n",
      "Epoch  100  loss  1.8495565326822088 correct 50 Time per epoch 0.188248610496521\n",
      "Epoch  110  loss  2.3942707454495604 correct 47 Time per epoch 0.1566373348236084\n",
      "Epoch  120  loss  1.0981690192055171 correct 47 Time per epoch 0.118084716796875\n",
      "Epoch  130  loss  1.4690774441386465 correct 49 Time per epoch 0.11915571689605713\n",
      "Epoch  140  loss  1.8279052712438375 correct 48 Time per epoch 0.11936712265014648\n",
      "Epoch  150  loss  1.549738276093373 correct 47 Time per epoch 0.12140779495239258\n",
      "Epoch  160  loss  1.6774991053733475 correct 50 Time per epoch 0.11907682418823243\n",
      "Epoch  170  loss  1.997653197230314 correct 48 Time per epoch 0.11867866516113282\n",
      "Epoch  180  loss  0.6830524800190532 correct 48 Time per epoch 0.1192049503326416\n",
      "Epoch  190  loss  1.2332131857724176 correct 50 Time per epoch 0.14886963367462158\n",
      "Epoch  200  loss  0.8331625222090857 correct 48 Time per epoch 0.19944820404052735\n",
      "Epoch  210  loss  2.179671824114534 correct 47 Time per epoch 0.12128193378448486\n",
      "Epoch  220  loss  1.290679286002375 correct 49 Time per epoch 0.12162904739379883\n",
      "Epoch  230  loss  1.0441280975794944 correct 50 Time per epoch 0.11998724937438965\n",
      "Epoch  240  loss  1.5425489802518713 correct 48 Time per epoch 0.11952309608459473\n",
      "Epoch  250  loss  0.5032168673034659 correct 50 Time per epoch 0.12177577018737792\n",
      "Epoch  260  loss  1.3158919401176696 correct 48 Time per epoch 0.12483925819396972\n",
      "Epoch  270  loss  1.940937344700474 correct 49 Time per epoch 0.1161881923675537\n",
      "Epoch  280  loss  1.7571371582267115 correct 48 Time per epoch 0.11650233268737793\n",
      "Epoch  290  loss  1.5670317658417048 correct 49 Time per epoch 0.18432722091674805\n",
      "Epoch  300  loss  0.3443326506523604 correct 49 Time per epoch 0.17966887950897217\n",
      "Epoch  310  loss  2.297542715312856 correct 47 Time per epoch 0.11801111698150635\n",
      "Epoch  320  loss  1.0134241841378278 correct 50 Time per epoch 0.1198911190032959\n",
      "Epoch  330  loss  2.3826357470717943 correct 48 Time per epoch 0.11989438533782959\n",
      "Epoch  340  loss  1.6724125547625721 correct 48 Time per epoch 0.1191814661026001\n",
      "Epoch  350  loss  0.9145743967362193 correct 49 Time per epoch 0.11872429847717285\n",
      "Epoch  360  loss  0.1480268609576475 correct 50 Time per epoch 0.11805486679077148\n",
      "Epoch  370  loss  0.21150701087148185 correct 48 Time per epoch 0.11776306629180908\n",
      "Epoch  380  loss  3.1533191319910374 correct 48 Time per epoch 0.1311892032623291\n",
      "Epoch  390  loss  2.80913092445702 correct 45 Time per epoch 0.23256187438964843\n",
      "Epoch  400  loss  0.8271929613600563 correct 49 Time per epoch 0.12296621799468994\n",
      "Epoch  410  loss  1.0745382289338106 correct 49 Time per epoch 0.120625901222229\n",
      "Epoch  420  loss  0.3886742028591402 correct 49 Time per epoch 0.11828255653381348\n",
      "Epoch  430  loss  0.37466113539860524 correct 50 Time per epoch 0.11663808822631835\n",
      "Epoch  440  loss  1.0651466401835046 correct 50 Time per epoch 0.12049369812011719\n",
      "Epoch  450  loss  0.2913659388317869 correct 48 Time per epoch 0.12022242546081544\n",
      "Epoch  460  loss  0.4868755994390212 correct 49 Time per epoch 0.12141685485839844\n",
      "Epoch  470  loss  0.21966644673149133 correct 48 Time per epoch 0.11787593364715576\n",
      "Epoch  480  loss  1.4262520704775954 correct 48 Time per epoch 0.17821290493011474\n",
      "Epoch  490  loss  0.3155911563738448 correct 48 Time per epoch 0.18151867389678955\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 100 --DATASET split --RATE 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iS9NKsjEQF6",
    "outputId": "e2842b48-7691-4497-898b-1f96f5c5f9bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 100 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Epoch  0  loss  6.481937763055415 correct 39 Time per epoch 0.407978892326355\n",
      "Epoch  10  loss  2.7783638238402455 correct 48 Time per epoch 1.6973078012466432\n",
      "Epoch  20  loss  1.0816036561063862 correct 49 Time per epoch 1.646232008934021\n",
      "Epoch  30  loss  0.986209685346125 correct 49 Time per epoch 1.725732398033142\n",
      "Epoch  40  loss  0.7953561445234931 correct 49 Time per epoch 1.6460023880004884\n",
      "Epoch  50  loss  0.7673651858198178 correct 49 Time per epoch 1.644883131980896\n",
      "Epoch  60  loss  0.12338980722029219 correct 50 Time per epoch 1.7300977945327758\n",
      "Epoch  70  loss  0.8333943450898526 correct 50 Time per epoch 1.6368321180343628\n",
      "Epoch  80  loss  0.6669456865557821 correct 50 Time per epoch 1.6784167289733887\n",
      "Epoch  90  loss  0.6832788063552717 correct 50 Time per epoch 1.6867339372634889\n",
      "Epoch  100  loss  0.16385346808941528 correct 50 Time per epoch 1.6686639070510865\n",
      "Epoch  110  loss  0.22615403537376305 correct 50 Time per epoch 1.7282199621200562\n",
      "Epoch  120  loss  0.6834386563126376 correct 50 Time per epoch 1.6581048488616943\n",
      "Epoch  130  loss  0.14723125203196755 correct 50 Time per epoch 1.6514455318450927\n",
      "Epoch  140  loss  0.04766557836932199 correct 50 Time per epoch 1.7182116746902465\n",
      "Epoch  150  loss  0.12625481614669878 correct 50 Time per epoch 1.634512233734131\n",
      "Epoch  160  loss  0.15092615527917652 correct 50 Time per epoch 1.6575533866882324\n",
      "Epoch  170  loss  0.26090173967241853 correct 50 Time per epoch 1.709930658340454\n",
      "Epoch  180  loss  0.096137494114446 correct 50 Time per epoch 1.6487049818038941\n",
      "Epoch  190  loss  0.09586195533021093 correct 50 Time per epoch 1.7170356512069702\n",
      "Epoch  200  loss  0.5037094074539425 correct 50 Time per epoch 1.6214834213256837\n",
      "Epoch  210  loss  0.4618567660593682 correct 50 Time per epoch 1.657362174987793\n",
      "Epoch  220  loss  0.09981655135537293 correct 50 Time per epoch 1.6847610950469971\n",
      "Epoch  230  loss  0.09734649982862023 correct 50 Time per epoch 1.6181921720504762\n",
      "Epoch  240  loss  0.06743315653177287 correct 50 Time per epoch 1.6307124614715576\n",
      "Epoch  250  loss  0.44291893673776295 correct 50 Time per epoch 1.7008199214935302\n",
      "Epoch  260  loss  0.4202826488124952 correct 50 Time per epoch 1.6463300943374635\n",
      "Epoch  270  loss  0.396511118303373 correct 50 Time per epoch 1.6581544399261474\n",
      "Epoch  280  loss  0.1917985603428767 correct 50 Time per epoch 1.6934150457382202\n",
      "Epoch  290  loss  0.05907425824555271 correct 50 Time per epoch 1.6317212581634521\n",
      "Epoch  300  loss  0.3870556674702017 correct 50 Time per epoch 1.759246301651001\n",
      "Epoch  310  loss  0.15294605361689856 correct 50 Time per epoch 1.695751714706421\n",
      "Epoch  320  loss  0.25700866354341395 correct 50 Time per epoch 1.6252236127853394\n",
      "Epoch  330  loss  0.007714909901928439 correct 50 Time per epoch 1.717577338218689\n",
      "Epoch  340  loss  0.04721945731791985 correct 50 Time per epoch 1.6425475120544433\n",
      "Epoch  350  loss  0.006292965951411999 correct 50 Time per epoch 1.6623739719390869\n",
      "Epoch  360  loss  0.002311311340800275 correct 50 Time per epoch 1.6760843753814698\n",
      "Epoch  370  loss  0.402144765704951 correct 50 Time per epoch 1.648738646507263\n",
      "Epoch  380  loss  0.10342010055280702 correct 50 Time per epoch 1.7165451288223266\n",
      "Epoch  390  loss  0.03739122234126673 correct 50 Time per epoch 1.6340643167495728\n",
      "Epoch  400  loss  0.005288027628491001 correct 50 Time per epoch 1.7120745658874512\n",
      "Epoch  410  loss  0.2577377294878063 correct 50 Time per epoch 1.7025496244430542\n",
      "Epoch  420  loss  0.04441809465501527 correct 50 Time per epoch 1.636440896987915\n",
      "Epoch  430  loss  0.02937640852519877 correct 50 Time per epoch 1.6487253665924073\n",
      "Epoch  440  loss  0.03441096443892534 correct 50 Time per epoch 1.71208758354187\n",
      "Epoch  450  loss  0.0023742632090897682 correct 50 Time per epoch 1.6279669284820557\n",
      "Epoch  460  loss  0.043143722548246874 correct 50 Time per epoch 1.6286793231964112\n",
      "Epoch  470  loss  0.22760163236245928 correct 50 Time per epoch 1.6977510452270508\n",
      "Epoch  480  loss  0.006437988702337798 correct 50 Time per epoch 1.620657777786255\n",
      "Epoch  490  loss  0.2815465536357415 correct 50 Time per epoch 1.6278005599975587\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 100 --DATASET simple --RATE 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5T1I7cAmtOcW",
    "outputId": "48bc5e3d-f2ec-4715-8735-49cd8f335f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  loss  4.072993020474098 correct 46 Time per epoch 1.821043109893799\n",
      "Epoch  10  loss  2.8417578866380286 correct 46 Time per epoch 0.11979763507843018\n",
      "Epoch  20  loss  0.9534351896594562 correct 48 Time per epoch 0.11746294498443603\n",
      "Epoch  30  loss  0.5169770608415106 correct 48 Time per epoch 0.11360929012298585\n",
      "Epoch  40  loss  2.0495912637027742 correct 47 Time per epoch 0.11644368171691895\n",
      "Epoch  50  loss  0.6144947794805771 correct 47 Time per epoch 0.11601006984710693\n",
      "Epoch  60  loss  1.7388608735493079 correct 47 Time per epoch 0.18784208297729493\n",
      "Epoch  70  loss  1.1724007059865589 correct 47 Time per epoch 0.16030232906341552\n",
      "Epoch  80  loss  2.972880481227632 correct 49 Time per epoch 0.11891570091247558\n",
      "Epoch  90  loss  1.4654272735465166 correct 48 Time per epoch 0.12147533893585205\n",
      "Epoch  100  loss  0.43477396195301027 correct 48 Time per epoch 0.11659362316131591\n",
      "Epoch  110  loss  0.2175450620821583 correct 49 Time per epoch 0.11808733940124512\n",
      "Epoch  120  loss  0.25516654394823984 correct 49 Time per epoch 0.11551165580749512\n",
      "Epoch  130  loss  0.9605996435978612 correct 49 Time per epoch 0.15984010696411133\n",
      "Epoch  140  loss  0.9896400725326358 correct 48 Time per epoch 0.11587059497833252\n",
      "Epoch  150  loss  1.7619590495680257 correct 47 Time per epoch 0.15662240982055664\n",
      "Epoch  160  loss  1.333117719737331 correct 48 Time per epoch 0.1966404676437378\n",
      "Epoch  170  loss  0.029819988544924774 correct 49 Time per epoch 0.11687407493591309\n",
      "Epoch  180  loss  1.6243476538518842 correct 49 Time per epoch 0.12033782005310059\n",
      "Epoch  190  loss  0.16143745710509017 correct 48 Time per epoch 0.11686105728149414\n",
      "Epoch  200  loss  0.7241263642060928 correct 49 Time per epoch 0.11746079921722412\n",
      "Epoch  210  loss  0.0027542869472177685 correct 49 Time per epoch 0.11815938949584961\n",
      "Epoch  220  loss  0.08520076905991586 correct 49 Time per epoch 0.12468860149383545\n",
      "Epoch  230  loss  0.28983069526545785 correct 49 Time per epoch 0.13358213901519775\n",
      "Epoch  240  loss  1.108315974326822 correct 49 Time per epoch 0.11897244453430175\n",
      "Epoch  250  loss  0.13724821280375488 correct 49 Time per epoch 0.21983985900878905\n",
      "Epoch  260  loss  0.290325780391262 correct 49 Time per epoch 0.1537280797958374\n",
      "Epoch  270  loss  1.2705145980103114 correct 49 Time per epoch 0.1318354606628418\n",
      "Epoch  280  loss  1.3032682808649576 correct 48 Time per epoch 0.1152001142501831\n",
      "Epoch  290  loss  2.1621838828338382 correct 49 Time per epoch 0.1150890588760376\n",
      "Epoch  300  loss  0.5567366486986053 correct 49 Time per epoch 0.14057817459106445\n",
      "Epoch  310  loss  0.18852926850184362 correct 49 Time per epoch 0.1165238857269287\n",
      "Epoch  320  loss  0.8659943781062481 correct 49 Time per epoch 0.1178093671798706\n",
      "Epoch  330  loss  0.2237755699552302 correct 49 Time per epoch 0.15357627868652343\n",
      "Epoch  340  loss  0.5562096310196353 correct 49 Time per epoch 0.2553840160369873\n",
      "Epoch  350  loss  0.2948144202740538 correct 49 Time per epoch 0.11846275329589843\n",
      "Epoch  360  loss  1.8988081448932967 correct 48 Time per epoch 0.12019689083099365\n",
      "Epoch  370  loss  0.5670791128016917 correct 49 Time per epoch 0.1173095464706421\n",
      "Epoch  380  loss  1.461336990323139 correct 49 Time per epoch 0.1184088945388794\n",
      "Epoch  390  loss  0.03353737848822169 correct 49 Time per epoch 0.11715047359466553\n",
      "Epoch  400  loss  0.6752423989473538 correct 49 Time per epoch 0.12100212574005127\n",
      "Epoch  410  loss  0.1696513306973005 correct 49 Time per epoch 0.1223360538482666\n",
      "Epoch  420  loss  0.005829809499994377 correct 47 Time per epoch 0.11998207569122314\n",
      "Epoch  430  loss  1.9659014345514274 correct 48 Time per epoch 0.18945207595825195\n",
      "Epoch  440  loss  1.0327033992391215 correct 49 Time per epoch 0.1649810791015625\n",
      "Epoch  450  loss  2.6409182244951306 correct 48 Time per epoch 0.11606917381286622\n",
      "Epoch  460  loss  0.19311624694023186 correct 49 Time per epoch 0.11735038757324219\n",
      "Epoch  470  loss  0.44435388749396537 correct 49 Time per epoch 0.11677155494689942\n",
      "Epoch  480  loss  0.6983933681193084 correct 49 Time per epoch 0.11730124950408935\n",
      "Epoch  490  loss  0.0015200086104271218 correct 49 Time per epoch 0.11563563346862793\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 100 --DATASET simple --RATE 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sBT4PecDtQS3",
    "outputId": "46f625da-978c-4044-e2c1-b0ef0ffa6003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 100 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Epoch  0  loss  6.280394010416758 correct 27 Time per epoch 0.4752765417098999\n",
      "Epoch  10  loss  4.54587621740805 correct 43 Time per epoch 1.6597156763076781\n",
      "Epoch  20  loss  5.696152755112369 correct 44 Time per epoch 1.6388537168502808\n",
      "Epoch  30  loss  4.7690138755906375 correct 47 Time per epoch 1.776206660270691\n",
      "Epoch  40  loss  4.3878708626221155 correct 47 Time per epoch 1.6316620349884032\n",
      "Epoch  50  loss  1.440041113625051 correct 47 Time per epoch 1.695201563835144\n",
      "Epoch  60  loss  2.7092722870949597 correct 47 Time per epoch 1.6569730281829833\n",
      "Epoch  70  loss  3.504960246264046 correct 47 Time per epoch 1.6237014770507812\n",
      "Epoch  80  loss  1.9734175857999503 correct 47 Time per epoch 1.724666428565979\n",
      "Epoch  90  loss  1.8998279361511983 correct 47 Time per epoch 1.6317059993743896\n",
      "Epoch  100  loss  1.9546704568559972 correct 48 Time per epoch 1.6304309606552123\n",
      "Epoch  110  loss  2.0823363968192625 correct 49 Time per epoch 1.7225021362304687\n",
      "Epoch  120  loss  1.522797453870397 correct 50 Time per epoch 1.6637585639953614\n",
      "Epoch  130  loss  1.5563294674158006 correct 49 Time per epoch 1.6589678525924683\n",
      "Epoch  140  loss  2.3356967576579954 correct 49 Time per epoch 1.7435626268386841\n",
      "Epoch  150  loss  1.4486449502040997 correct 49 Time per epoch 1.682109260559082\n",
      "Epoch  160  loss  1.3332770018910807 correct 49 Time per epoch 1.6654359817504882\n",
      "Epoch  170  loss  1.0197150361371938 correct 50 Time per epoch 1.7630751132965088\n",
      "Epoch  180  loss  0.856274390901779 correct 50 Time per epoch 1.6574673652648926\n",
      "Epoch  190  loss  0.8247612216628917 correct 50 Time per epoch 1.6756616353988647\n",
      "Epoch  200  loss  0.5998356273262913 correct 50 Time per epoch 1.6954685926437378\n",
      "Epoch  210  loss  1.2734275449865227 correct 50 Time per epoch 1.7357024431228638\n",
      "Epoch  220  loss  0.8724950949226408 correct 50 Time per epoch 1.7304427862167358\n",
      "Epoch  230  loss  1.4340386425434652 correct 50 Time per epoch 1.6501287460327148\n",
      "Epoch  240  loss  0.8234807492644918 correct 50 Time per epoch 1.6598962783813476\n",
      "Epoch  250  loss  0.4140581992810794 correct 50 Time per epoch 1.7253230571746827\n",
      "Epoch  260  loss  0.7995631873155827 correct 50 Time per epoch 1.6532833099365234\n",
      "Epoch  270  loss  0.5384153162146605 correct 50 Time per epoch 1.6363509178161622\n",
      "Epoch  280  loss  0.7807404948686034 correct 50 Time per epoch 1.729175066947937\n",
      "Epoch  290  loss  0.08110074482053535 correct 50 Time per epoch 1.6606518507003785\n",
      "Epoch  300  loss  0.32281537856608444 correct 50 Time per epoch 1.6889002799987793\n",
      "Epoch  310  loss  0.5771569695951806 correct 50 Time per epoch 1.7311749935150147\n",
      "Epoch  320  loss  0.350838994296919 correct 50 Time per epoch 1.6769214153289795\n",
      "Epoch  330  loss  0.47394295691354243 correct 50 Time per epoch 1.7438384771347046\n",
      "Epoch  340  loss  0.27919117336073473 correct 50 Time per epoch 1.6917418956756591\n",
      "Epoch  350  loss  0.49845938704009907 correct 50 Time per epoch 1.67563316822052\n",
      "Epoch  360  loss  0.4089068655361512 correct 50 Time per epoch 1.7808459281921387\n",
      "Epoch  370  loss  0.5570826088473483 correct 50 Time per epoch 1.6767160415649414\n",
      "Epoch  380  loss  0.3184246198334393 correct 50 Time per epoch 1.739782953262329\n",
      "Epoch  390  loss  0.7447183123656521 correct 50 Time per epoch 1.6881900310516358\n",
      "Epoch  400  loss  0.22381238941523887 correct 50 Time per epoch 1.7551891565322877\n",
      "Epoch  410  loss  0.14223622537157649 correct 50 Time per epoch 1.7358999252319336\n",
      "Epoch  420  loss  0.4529982840736022 correct 50 Time per epoch 1.650507926940918\n",
      "Epoch  430  loss  0.22097922003217196 correct 50 Time per epoch 1.7256225109100343\n",
      "Epoch  440  loss  0.07050433179672828 correct 50 Time per epoch 1.6815274715423585\n",
      "Epoch  450  loss  0.6791687507084176 correct 50 Time per epoch 1.6609324216842651\n",
      "Epoch  460  loss  0.4586662998718075 correct 50 Time per epoch 1.7471157550811767\n",
      "Epoch  470  loss  0.10269269854401873 correct 50 Time per epoch 1.6757093906402587\n",
      "Epoch  480  loss  0.3285267750070468 correct 50 Time per epoch 1.699565625190735\n",
      "Epoch  490  loss  0.3311483256589699 correct 50 Time per epoch 1.7181056499481202\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 100 --DATASET xor --RATE 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "F5UX_f85tWSL",
    "outputId": "a2f86b76-5412-42df-91d7-d42297742181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  loss  7.833886601666596 correct 30 Time per epoch 1.5229301929473877\n",
      "Epoch  10  loss  5.606696817149911 correct 42 Time per epoch 0.11924517154693604\n",
      "Epoch  20  loss  6.68105608872518 correct 41 Time per epoch 0.11962106227874755\n",
      "Epoch  30  loss  4.251635905327726 correct 44 Time per epoch 0.15417258739471434\n",
      "Epoch  40  loss  4.921150473005961 correct 41 Time per epoch 0.19574248790740967\n",
      "Epoch  50  loss  4.882515965434023 correct 45 Time per epoch 0.11870090961456299\n",
      "Epoch  60  loss  2.1268739909296213 correct 45 Time per epoch 0.11768028736114503\n",
      "Epoch  70  loss  2.918286314982733 correct 46 Time per epoch 0.12138838768005371\n",
      "Epoch  80  loss  2.2431118076475496 correct 45 Time per epoch 0.11948721408843994\n",
      "Epoch  90  loss  3.7745697115512544 correct 45 Time per epoch 0.11835236549377441\n",
      "Epoch  100  loss  2.398740677853622 correct 48 Time per epoch 0.11851356029510499\n",
      "Epoch  110  loss  1.7489450976167875 correct 48 Time per epoch 0.11992745399475098\n",
      "Epoch  120  loss  2.1148395267343036 correct 48 Time per epoch 0.11896333694458008\n",
      "Epoch  130  loss  0.5012782866341366 correct 47 Time per epoch 0.1995089054107666\n",
      "Epoch  140  loss  1.1999808955245561 correct 48 Time per epoch 0.1437612771987915\n",
      "Epoch  150  loss  2.8088040359218054 correct 48 Time per epoch 0.12161428928375244\n",
      "Epoch  160  loss  1.1858969005741438 correct 48 Time per epoch 0.12199544906616211\n",
      "Epoch  170  loss  1.2750897621368733 correct 49 Time per epoch 0.11999475955963135\n",
      "Epoch  180  loss  1.1210966570964789 correct 49 Time per epoch 0.1210564136505127\n",
      "Epoch  190  loss  2.86253503473177 correct 48 Time per epoch 0.12016117572784424\n",
      "Epoch  200  loss  0.854128623021924 correct 48 Time per epoch 0.12246372699737548\n",
      "Epoch  210  loss  0.7657964072352205 correct 48 Time per epoch 0.12391691207885742\n",
      "Epoch  220  loss  0.5123072098702285 correct 48 Time per epoch 0.19438583850860597\n",
      "Epoch  230  loss  1.3270099685805061 correct 50 Time per epoch 0.16785409450531005\n",
      "Epoch  240  loss  1.7393459438811378 correct 50 Time per epoch 0.12720136642456054\n",
      "Epoch  250  loss  0.39245090862845233 correct 49 Time per epoch 0.1218914270401001\n",
      "Epoch  260  loss  0.9229339990694443 correct 48 Time per epoch 0.13014373779296876\n",
      "Epoch  270  loss  1.78313719117919 correct 48 Time per epoch 0.11975512504577637\n",
      "Epoch  280  loss  0.17859485757681123 correct 49 Time per epoch 0.12410197257995606\n",
      "Epoch  290  loss  0.4773990107969874 correct 49 Time per epoch 0.11937918663024902\n",
      "Epoch  300  loss  0.744352622998539 correct 50 Time per epoch 0.12117195129394531\n",
      "Epoch  310  loss  0.8198126234629748 correct 49 Time per epoch 0.1822735548019409\n",
      "Epoch  320  loss  0.26341487242022893 correct 48 Time per epoch 0.1757634162902832\n",
      "Epoch  330  loss  0.4188268289417224 correct 49 Time per epoch 0.12256486415863037\n",
      "Epoch  340  loss  0.745941529409921 correct 49 Time per epoch 0.11639883518218994\n",
      "Epoch  350  loss  1.3039709730467781 correct 50 Time per epoch 0.1174548625946045\n",
      "Epoch  360  loss  0.3972008438457014 correct 48 Time per epoch 0.1175736665725708\n",
      "Epoch  370  loss  1.596022414590836 correct 49 Time per epoch 0.11665129661560059\n",
      "Epoch  380  loss  1.0420417591709863 correct 49 Time per epoch 0.11793045997619629\n",
      "Epoch  390  loss  0.29529385120348417 correct 49 Time per epoch 0.11733434200286866\n",
      "Epoch  400  loss  1.8117382685644077 correct 49 Time per epoch 0.12164540290832519\n",
      "Epoch  410  loss  0.4703789780031911 correct 50 Time per epoch 0.2247083902359009\n",
      "Epoch  420  loss  1.5202468661826536 correct 49 Time per epoch 0.12026774883270264\n",
      "Epoch  430  loss  1.3959784324596949 correct 49 Time per epoch 0.11760983467102051\n",
      "Epoch  440  loss  0.5639214836043898 correct 49 Time per epoch 0.1201460599899292\n",
      "Epoch  450  loss  0.33589337043478684 correct 48 Time per epoch 0.11609315872192383\n",
      "Epoch  460  loss  0.38985212153280335 correct 48 Time per epoch 0.12106122970581054\n",
      "Epoch  470  loss  0.7473232001626022 correct 49 Time per epoch 0.1175995111465454\n",
      "Epoch  480  loss  0.2275896456521271 correct 49 Time per epoch 0.11702971458435059\n",
      "Epoch  490  loss  0.01898596464758289 correct 49 Time per epoch 0.11677744388580322\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 100 --DATASET xor --RATE 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMU9KaN18iVp",
    "outputId": "9e0a2d23-49fc-443d-ba81-72cc1fcc9203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 13 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 13 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 63 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 63 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 63 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 49 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 13 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 14 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.12/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Epoch  0  loss  2.5601119825297824 correct 43 Time per epoch 0.47141706943511963\n",
      "Epoch  10  loss  0.3875193316599459 correct 50 Time per epoch 2.0123230695724486\n",
      "Epoch  20  loss  0.2885238931774418 correct 50 Time per epoch 1.8433511018753053\n",
      "Epoch  30  loss  0.3477124336633688 correct 50 Time per epoch 1.7443787336349488\n",
      "Epoch  40  loss  0.1565048763023117 correct 50 Time per epoch 1.8733482360839844\n",
      "Epoch  50  loss  0.17623620256826691 correct 50 Time per epoch 1.74590744972229\n",
      "Epoch  60  loss  0.019831957329596084 correct 50 Time per epoch 1.816489291191101\n",
      "Epoch  70  loss  0.10439441415972953 correct 50 Time per epoch 1.7475043773651122\n",
      "Epoch  80  loss  0.08338225970576824 correct 50 Time per epoch 1.8297606706619263\n",
      "Epoch  90  loss  0.0033090558053899214 correct 50 Time per epoch 1.787989568710327\n",
      "Epoch  100  loss  0.1605880115358843 correct 50 Time per epoch 1.7761601448059081\n",
      "Epoch  110  loss  0.13181051394978918 correct 50 Time per epoch 1.847226619720459\n",
      "Epoch  120  loss  0.0005527584063520456 correct 50 Time per epoch 1.7739270210266114\n",
      "Epoch  130  loss  0.03385889349668325 correct 50 Time per epoch 1.941284465789795\n",
      "Epoch  140  loss  0.07809793754532962 correct 50 Time per epoch 1.7462730884552002\n",
      "Epoch  150  loss  0.05421449757858084 correct 50 Time per epoch 1.8089396238327027\n",
      "Epoch  160  loss  0.07380067164371795 correct 50 Time per epoch 1.7679046869277955\n",
      "Epoch  170  loss  0.055892067295157916 correct 50 Time per epoch 1.747575855255127\n",
      "Epoch  180  loss  0.06526801401685184 correct 50 Time per epoch 1.8322970151901246\n",
      "Epoch  190  loss  0.01719348543372224 correct 50 Time per epoch 1.7359487771987916\n",
      "Epoch  200  loss  0.009741595067736676 correct 50 Time per epoch 1.808492374420166\n",
      "Epoch  210  loss  0.07485484827115735 correct 50 Time per epoch 1.7503846168518067\n",
      "Epoch  220  loss  0.052397090945210535 correct 50 Time per epoch 1.786918544769287\n",
      "Epoch  230  loss  0.008293924847965234 correct 50 Time per epoch 1.7690865039825439\n",
      "Epoch  240  loss  0.023704817131458493 correct 50 Time per epoch 1.7402574062347411\n",
      "Epoch  250  loss  0.03409195763980557 correct 50 Time per epoch 1.8438809156417846\n",
      "Epoch  260  loss  0.044656473839558994 correct 50 Time per epoch 1.7611313581466674\n",
      "Epoch  270  loss  0.003464592622327433 correct 50 Time per epoch 1.845083522796631\n",
      "Epoch  280  loss  0.007668650097872257 correct 50 Time per epoch 1.766694474220276\n",
      "Epoch  290  loss  0.003430450640882463 correct 50 Time per epoch 1.8470298290252685\n",
      "Epoch  300  loss  0.010976191293239871 correct 50 Time per epoch 1.865936827659607\n",
      "Epoch  310  loss  0.007096300004460443 correct 50 Time per epoch 1.8145889520645142\n",
      "Epoch  320  loss  0.054818772272228325 correct 50 Time per epoch 1.7718312978744506\n",
      "Epoch  330  loss  0.006025082876673667 correct 50 Time per epoch 1.7606521844863892\n",
      "Epoch  340  loss  0.05881882741940195 correct 50 Time per epoch 1.839719796180725\n",
      "Epoch  350  loss  0.05874862050911139 correct 50 Time per epoch 1.7404290914535523\n",
      "Epoch  360  loss  0.0030708418274423273 correct 50 Time per epoch 1.8393359661102295\n",
      "Epoch  370  loss  0.033809723082986784 correct 50 Time per epoch 1.7310850620269775\n",
      "Epoch  380  loss  0.010926136295700994 correct 50 Time per epoch 1.7871577739715576\n",
      "Epoch  390  loss  0.0343527745300386 correct 50 Time per epoch 1.773015522956848\n",
      "Epoch  400  loss  0.003725438945055405 correct 50 Time per epoch 1.7370295524597168\n",
      "Epoch  410  loss  0.011246878181417038 correct 50 Time per epoch 1.8175803899765015\n",
      "Epoch  420  loss  0.0193476241068913 correct 50 Time per epoch 1.7394263982772826\n",
      "Epoch  430  loss  0.05253097446593277 correct 50 Time per epoch 1.8454719066619873\n",
      "Epoch  440  loss  0.026622293113952054 correct 50 Time per epoch 1.7558518171310424\n",
      "Epoch  450  loss  0.03564003887282088 correct 50 Time per epoch 1.8065390586853027\n",
      "Epoch  460  loss  0.00020557004568938738 correct 50 Time per epoch 1.7312028884887696\n",
      "Epoch  470  loss  0.022234071313934987 correct 50 Time per epoch 1.7999560832977295\n",
      "Epoch  480  loss  0.03288229174604747 correct 50 Time per epoch 1.8154486179351808\n",
      "Epoch  490  loss  0.00015305609996510392 correct 50 Time per epoch 1.7185826539993285\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 200 --DATASET simple --RATE 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a7sti9Dy7Vc",
    "outputId": "eb4740d1-d11e-46e0-d4f4-e7d3cc66c604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  loss  16.4800989953874 correct 38 Time per epoch 1.5370167016983032\n",
      "Epoch  10  loss  0.39785259655488237 correct 50 Time per epoch 0.2715207576751709\n",
      "Epoch  20  loss  0.12195639885530515 correct 50 Time per epoch 0.3928703784942627\n",
      "Epoch  30  loss  0.31022076830778933 correct 50 Time per epoch 0.2736185312271118\n",
      "Epoch  40  loss  0.05699249132931301 correct 50 Time per epoch 0.2720853090286255\n",
      "Epoch  50  loss  0.24944114057222483 correct 50 Time per epoch 0.27010796070098875\n",
      "Epoch  60  loss  0.3423720385672292 correct 50 Time per epoch 0.38702704906463625\n",
      "Epoch  70  loss  0.061209128318553734 correct 50 Time per epoch 0.27201783657073975\n",
      "Epoch  80  loss  0.10117941396405244 correct 50 Time per epoch 0.2702460527420044\n",
      "Epoch  90  loss  0.17192814735870576 correct 50 Time per epoch 0.2732026815414429\n",
      "Epoch  100  loss  0.11245954938722524 correct 50 Time per epoch 0.37405245304107665\n",
      "Epoch  110  loss  0.23282353038079606 correct 50 Time per epoch 0.2960777997970581\n",
      "Epoch  120  loss  0.050516817206653686 correct 50 Time per epoch 0.27211310863494875\n",
      "Epoch  130  loss  0.003332288271033286 correct 50 Time per epoch 0.2728134632110596\n",
      "Epoch  140  loss  0.10587232868098713 correct 50 Time per epoch 0.33142409324645994\n",
      "Epoch  150  loss  0.00504857351057359 correct 50 Time per epoch 0.33056039810180665\n",
      "Epoch  160  loss  0.01871779328317779 correct 50 Time per epoch 0.27343335151672366\n",
      "Epoch  170  loss  0.004268587579838819 correct 50 Time per epoch 0.2745417833328247\n",
      "Epoch  180  loss  0.06282651635585458 correct 50 Time per epoch 0.30839076042175295\n",
      "Epoch  190  loss  0.05671066324630268 correct 50 Time per epoch 0.3609639883041382\n",
      "Epoch  200  loss  0.10740604736279863 correct 50 Time per epoch 0.27433784008026124\n",
      "Epoch  210  loss  0.13955097890367277 correct 50 Time per epoch 0.2742986917495728\n",
      "Epoch  220  loss  0.09374705062327036 correct 50 Time per epoch 0.27635464668273924\n",
      "Epoch  230  loss  0.030717948041920334 correct 50 Time per epoch 0.3919733762741089\n",
      "Epoch  240  loss  0.048087894154764575 correct 50 Time per epoch 0.273266863822937\n",
      "Epoch  250  loss  0.03872849130572199 correct 50 Time per epoch 0.2725456953048706\n",
      "Epoch  260  loss  0.09725968511892806 correct 50 Time per epoch 0.27871978282928467\n",
      "Epoch  270  loss  0.007223151509706272 correct 50 Time per epoch 0.39563310146331787\n",
      "Epoch  280  loss  0.04388342994757184 correct 50 Time per epoch 0.2689098358154297\n",
      "Epoch  290  loss  0.042873492161255994 correct 50 Time per epoch 0.27824814319610597\n",
      "Epoch  300  loss  0.0006527997643945117 correct 50 Time per epoch 0.2748971223831177\n",
      "Epoch  310  loss  0.05775718892561606 correct 50 Time per epoch 0.39644060134887693\n",
      "Epoch  320  loss  0.000929413386225791 correct 50 Time per epoch 0.2781154870986938\n",
      "Epoch  330  loss  0.01443891498925031 correct 50 Time per epoch 0.27114531993865965\n",
      "Epoch  340  loss  0.028437414376311778 correct 50 Time per epoch 0.27302649021148684\n",
      "Epoch  350  loss  0.009362735585113581 correct 50 Time per epoch 0.3933796644210815\n",
      "Epoch  360  loss  0.022165290893563047 correct 50 Time per epoch 0.2698263883590698\n",
      "Epoch  370  loss  0.0309408364569507 correct 50 Time per epoch 0.27031357288360597\n",
      "Epoch  380  loss  0.020421484402632823 correct 50 Time per epoch 0.27276947498321535\n",
      "Epoch  390  loss  0.009010989167156636 correct 50 Time per epoch 0.39205996990203856\n",
      "Epoch  400  loss  0.028062076784529932 correct 50 Time per epoch 0.2755990982055664\n",
      "Epoch  410  loss  0.017858436228083596 correct 50 Time per epoch 0.2738886117935181\n",
      "Epoch  420  loss  0.01595788710578505 correct 50 Time per epoch 0.27085440158843993\n",
      "Epoch  430  loss  0.010981669314603044 correct 50 Time per epoch 0.3498138427734375\n",
      "Epoch  440  loss  0.0073597141156594645 correct 50 Time per epoch 0.3893049478530884\n",
      "Epoch  450  loss  0.001045879318996137 correct 50 Time per epoch 0.30714950561523435\n",
      "Epoch  460  loss  0.028332616492490064 correct 50 Time per epoch 0.26844699382781984\n",
      "Epoch  470  loss  0.006705242311157467 correct 50 Time per epoch 0.39022910594940186\n",
      "Epoch  480  loss  0.05121780781112924 correct 50 Time per epoch 0.2701330423355103\n",
      "Epoch  490  loss  0.002480405627858726 correct 50 Time per epoch 0.27403204441070556\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd $DIR; PYTHONPATH=/content/$DIR python3.12 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 200 --DATASET simple --RATE 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oc2Djm7ty89u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}